{
  "best_global_step": 6000,
  "best_metric": 3.237149238586426,
  "best_model_checkpoint": "./pythia-70m-xsum-summarizer\\checkpoint-6000",
  "epoch": 2.0,
  "eval_steps": 500,
  "global_step": 6378,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.01568258448992394,
      "grad_norm": 3.0838098526000977,
      "learning_rate": 4.9e-05,
      "loss": 3.9976,
      "step": 50
    },
    {
      "epoch": 0.03136516897984788,
      "grad_norm": 2.8953194618225098,
      "learning_rate": 9.900000000000001e-05,
      "loss": 3.7327,
      "step": 100
    },
    {
      "epoch": 0.047047753469771816,
      "grad_norm": 3.26814341545105,
      "learning_rate": 9.921949665498567e-05,
      "loss": 3.5202,
      "step": 150
    },
    {
      "epoch": 0.06273033795969576,
      "grad_norm": 4.145023345947266,
      "learning_rate": 9.842306467027717e-05,
      "loss": 3.4118,
      "step": 200
    },
    {
      "epoch": 0.0784129224496197,
      "grad_norm": 2.3167665004730225,
      "learning_rate": 9.762663268556865e-05,
      "loss": 3.3816,
      "step": 250
    },
    {
      "epoch": 0.09409550693954363,
      "grad_norm": 2.6109447479248047,
      "learning_rate": 9.683020070086015e-05,
      "loss": 3.3525,
      "step": 300
    },
    {
      "epoch": 0.10977809142946758,
      "grad_norm": 2.3471171855926514,
      "learning_rate": 9.603376871615164e-05,
      "loss": 3.3654,
      "step": 350
    },
    {
      "epoch": 0.12546067591939153,
      "grad_norm": 2.3777003288269043,
      "learning_rate": 9.523733673144314e-05,
      "loss": 3.3581,
      "step": 400
    },
    {
      "epoch": 0.14114326040931546,
      "grad_norm": 2.0698161125183105,
      "learning_rate": 9.444090474673464e-05,
      "loss": 3.3457,
      "step": 450
    },
    {
      "epoch": 0.1568258448992394,
      "grad_norm": 1.952507495880127,
      "learning_rate": 9.364447276202613e-05,
      "loss": 3.3546,
      "step": 500
    },
    {
      "epoch": 0.1568258448992394,
      "eval_loss": 3.3275721073150635,
      "eval_runtime": 79.4181,
      "eval_samples_per_second": 142.688,
      "eval_steps_per_second": 17.842,
      "step": 500
    },
    {
      "epoch": 0.17250842938916333,
      "grad_norm": 1.837329626083374,
      "learning_rate": 9.284804077731763e-05,
      "loss": 3.3353,
      "step": 550
    },
    {
      "epoch": 0.18819101387908727,
      "grad_norm": 1.9941529035568237,
      "learning_rate": 9.205160879260912e-05,
      "loss": 3.3323,
      "step": 600
    },
    {
      "epoch": 0.2038735983690112,
      "grad_norm": 2.007993221282959,
      "learning_rate": 9.125517680790062e-05,
      "loss": 3.3254,
      "step": 650
    },
    {
      "epoch": 0.21955618285893516,
      "grad_norm": 1.6392555236816406,
      "learning_rate": 9.04587448231921e-05,
      "loss": 3.3186,
      "step": 700
    },
    {
      "epoch": 0.2352387673488591,
      "grad_norm": 1.6840972900390625,
      "learning_rate": 8.96623128384836e-05,
      "loss": 3.3279,
      "step": 750
    },
    {
      "epoch": 0.25092135183878306,
      "grad_norm": 1.8875778913497925,
      "learning_rate": 8.886588085377509e-05,
      "loss": 3.3166,
      "step": 800
    },
    {
      "epoch": 0.266603936328707,
      "grad_norm": 1.67531156539917,
      "learning_rate": 8.806944886906659e-05,
      "loss": 3.2883,
      "step": 850
    },
    {
      "epoch": 0.2822865208186309,
      "grad_norm": 1.9334440231323242,
      "learning_rate": 8.727301688435808e-05,
      "loss": 3.3011,
      "step": 900
    },
    {
      "epoch": 0.29796910530855486,
      "grad_norm": 1.6441844701766968,
      "learning_rate": 8.647658489964956e-05,
      "loss": 3.3003,
      "step": 950
    },
    {
      "epoch": 0.3136516897984788,
      "grad_norm": 1.7464228868484497,
      "learning_rate": 8.568015291494106e-05,
      "loss": 3.3086,
      "step": 1000
    },
    {
      "epoch": 0.3136516897984788,
      "eval_loss": 3.29571270942688,
      "eval_runtime": 74.4171,
      "eval_samples_per_second": 152.277,
      "eval_steps_per_second": 19.041,
      "step": 1000
    },
    {
      "epoch": 0.32933427428840273,
      "grad_norm": 1.7558780908584595,
      "learning_rate": 8.488372093023255e-05,
      "loss": 3.2928,
      "step": 1050
    },
    {
      "epoch": 0.34501685877832666,
      "grad_norm": 1.766316533088684,
      "learning_rate": 8.408728894552405e-05,
      "loss": 3.2913,
      "step": 1100
    },
    {
      "epoch": 0.3606994432682506,
      "grad_norm": 1.744620680809021,
      "learning_rate": 8.329085696081555e-05,
      "loss": 3.303,
      "step": 1150
    },
    {
      "epoch": 0.37638202775817453,
      "grad_norm": 1.6903270483016968,
      "learning_rate": 8.249442497610704e-05,
      "loss": 3.2947,
      "step": 1200
    },
    {
      "epoch": 0.39206461224809847,
      "grad_norm": 1.6174571514129639,
      "learning_rate": 8.169799299139854e-05,
      "loss": 3.2883,
      "step": 1250
    },
    {
      "epoch": 0.4077471967380224,
      "grad_norm": 1.6417573690414429,
      "learning_rate": 8.090156100669003e-05,
      "loss": 3.2941,
      "step": 1300
    },
    {
      "epoch": 0.4234297812279464,
      "grad_norm": 1.7246161699295044,
      "learning_rate": 8.010512902198153e-05,
      "loss": 3.2922,
      "step": 1350
    },
    {
      "epoch": 0.4391123657178703,
      "grad_norm": 1.5772159099578857,
      "learning_rate": 7.930869703727301e-05,
      "loss": 3.2792,
      "step": 1400
    },
    {
      "epoch": 0.45479495020779426,
      "grad_norm": 1.6978358030319214,
      "learning_rate": 7.851226505256451e-05,
      "loss": 3.2986,
      "step": 1450
    },
    {
      "epoch": 0.4704775346977182,
      "grad_norm": 1.8261994123458862,
      "learning_rate": 7.771583306785602e-05,
      "loss": 3.291,
      "step": 1500
    },
    {
      "epoch": 0.4704775346977182,
      "eval_loss": 3.2801835536956787,
      "eval_runtime": 74.9104,
      "eval_samples_per_second": 151.274,
      "eval_steps_per_second": 18.916,
      "step": 1500
    },
    {
      "epoch": 0.4861601191876421,
      "grad_norm": 1.5005124807357788,
      "learning_rate": 7.69194010831475e-05,
      "loss": 3.2785,
      "step": 1550
    },
    {
      "epoch": 0.5018427036775661,
      "grad_norm": 1.858622431755066,
      "learning_rate": 7.6122969098439e-05,
      "loss": 3.2827,
      "step": 1600
    },
    {
      "epoch": 0.51752528816749,
      "grad_norm": 1.5862797498703003,
      "learning_rate": 7.532653711373049e-05,
      "loss": 3.2595,
      "step": 1650
    },
    {
      "epoch": 0.533207872657414,
      "grad_norm": 1.7095167636871338,
      "learning_rate": 7.453010512902199e-05,
      "loss": 3.2848,
      "step": 1700
    },
    {
      "epoch": 0.5488904571473379,
      "grad_norm": 1.889440894126892,
      "learning_rate": 7.373367314431348e-05,
      "loss": 3.27,
      "step": 1750
    },
    {
      "epoch": 0.5645730416372619,
      "grad_norm": 1.5562390089035034,
      "learning_rate": 7.293724115960498e-05,
      "loss": 3.2743,
      "step": 1800
    },
    {
      "epoch": 0.5802556261271857,
      "grad_norm": 1.6698576211929321,
      "learning_rate": 7.214080917489646e-05,
      "loss": 3.2682,
      "step": 1850
    },
    {
      "epoch": 0.5959382106171097,
      "grad_norm": 1.631433129310608,
      "learning_rate": 7.134437719018796e-05,
      "loss": 3.2715,
      "step": 1900
    },
    {
      "epoch": 0.6116207951070336,
      "grad_norm": 1.9372628927230835,
      "learning_rate": 7.054794520547947e-05,
      "loss": 3.2733,
      "step": 1950
    },
    {
      "epoch": 0.6273033795969576,
      "grad_norm": 1.6705631017684937,
      "learning_rate": 6.975151322077095e-05,
      "loss": 3.2733,
      "step": 2000
    },
    {
      "epoch": 0.6273033795969576,
      "eval_loss": 3.268507480621338,
      "eval_runtime": 74.3157,
      "eval_samples_per_second": 152.485,
      "eval_steps_per_second": 19.067,
      "step": 2000
    },
    {
      "epoch": 0.6429859640868815,
      "grad_norm": 1.7888858318328857,
      "learning_rate": 6.895508123606245e-05,
      "loss": 3.2754,
      "step": 2050
    },
    {
      "epoch": 0.6586685485768055,
      "grad_norm": 1.9159164428710938,
      "learning_rate": 6.815864925135394e-05,
      "loss": 3.2724,
      "step": 2100
    },
    {
      "epoch": 0.6743511330667294,
      "grad_norm": 1.6953033208847046,
      "learning_rate": 6.736221726664544e-05,
      "loss": 3.2713,
      "step": 2150
    },
    {
      "epoch": 0.6900337175566533,
      "grad_norm": 1.6418911218643188,
      "learning_rate": 6.656578528193693e-05,
      "loss": 3.2654,
      "step": 2200
    },
    {
      "epoch": 0.7057163020465773,
      "grad_norm": 1.6542521715164185,
      "learning_rate": 6.576935329722841e-05,
      "loss": 3.2654,
      "step": 2250
    },
    {
      "epoch": 0.7213988865365012,
      "grad_norm": 1.7409470081329346,
      "learning_rate": 6.497292131251991e-05,
      "loss": 3.2786,
      "step": 2300
    },
    {
      "epoch": 0.7370814710264252,
      "grad_norm": 1.4668521881103516,
      "learning_rate": 6.41764893278114e-05,
      "loss": 3.2703,
      "step": 2350
    },
    {
      "epoch": 0.7527640555163491,
      "grad_norm": 1.5435206890106201,
      "learning_rate": 6.33800573431029e-05,
      "loss": 3.2692,
      "step": 2400
    },
    {
      "epoch": 0.768446640006273,
      "grad_norm": 1.5296238660812378,
      "learning_rate": 6.258362535839439e-05,
      "loss": 3.2861,
      "step": 2450
    },
    {
      "epoch": 0.7841292244961969,
      "grad_norm": 1.825919270515442,
      "learning_rate": 6.178719337368589e-05,
      "loss": 3.2618,
      "step": 2500
    },
    {
      "epoch": 0.7841292244961969,
      "eval_loss": 3.2604691982269287,
      "eval_runtime": 84.0145,
      "eval_samples_per_second": 134.881,
      "eval_steps_per_second": 16.866,
      "step": 2500
    },
    {
      "epoch": 0.7998118089861209,
      "grad_norm": 1.978314757347107,
      "learning_rate": 6.099076138897738e-05,
      "loss": 3.2667,
      "step": 2550
    },
    {
      "epoch": 0.8154943934760448,
      "grad_norm": 1.6865259408950806,
      "learning_rate": 6.0194329404268876e-05,
      "loss": 3.2644,
      "step": 2600
    },
    {
      "epoch": 0.8311769779659688,
      "grad_norm": 1.7264909744262695,
      "learning_rate": 5.939789741956038e-05,
      "loss": 3.267,
      "step": 2650
    },
    {
      "epoch": 0.8468595624558928,
      "grad_norm": 1.5081413984298706,
      "learning_rate": 5.8601465434851864e-05,
      "loss": 3.2555,
      "step": 2700
    },
    {
      "epoch": 0.8625421469458167,
      "grad_norm": 1.6564019918441772,
      "learning_rate": 5.7805033450143364e-05,
      "loss": 3.2587,
      "step": 2750
    },
    {
      "epoch": 0.8782247314357406,
      "grad_norm": 1.7105624675750732,
      "learning_rate": 5.700860146543485e-05,
      "loss": 3.2647,
      "step": 2800
    },
    {
      "epoch": 0.8939073159256645,
      "grad_norm": 1.758518099784851,
      "learning_rate": 5.621216948072635e-05,
      "loss": 3.2544,
      "step": 2850
    },
    {
      "epoch": 0.9095899004155885,
      "grad_norm": 1.5725523233413696,
      "learning_rate": 5.541573749601784e-05,
      "loss": 3.2545,
      "step": 2900
    },
    {
      "epoch": 0.9252724849055124,
      "grad_norm": 1.5718944072723389,
      "learning_rate": 5.461930551130934e-05,
      "loss": 3.2661,
      "step": 2950
    },
    {
      "epoch": 0.9409550693954364,
      "grad_norm": 1.609429955482483,
      "learning_rate": 5.3822873526600826e-05,
      "loss": 3.2515,
      "step": 3000
    },
    {
      "epoch": 0.9409550693954364,
      "eval_loss": 3.2547268867492676,
      "eval_runtime": 84.1369,
      "eval_samples_per_second": 134.685,
      "eval_steps_per_second": 16.842,
      "step": 3000
    },
    {
      "epoch": 0.9566376538853603,
      "grad_norm": 1.4572746753692627,
      "learning_rate": 5.3026441541892326e-05,
      "loss": 3.2522,
      "step": 3050
    },
    {
      "epoch": 0.9723202383752843,
      "grad_norm": 1.66818368434906,
      "learning_rate": 5.223000955718382e-05,
      "loss": 3.2579,
      "step": 3100
    },
    {
      "epoch": 0.9880028228652082,
      "grad_norm": 1.6488275527954102,
      "learning_rate": 5.1433577572475314e-05,
      "loss": 3.2595,
      "step": 3150
    },
    {
      "epoch": 1.0034501685877832,
      "grad_norm": 1.7070138454437256,
      "learning_rate": 5.063714558776681e-05,
      "loss": 3.2649,
      "step": 3200
    },
    {
      "epoch": 1.0191327530777072,
      "grad_norm": 1.5542733669281006,
      "learning_rate": 4.98407136030583e-05,
      "loss": 3.2512,
      "step": 3250
    },
    {
      "epoch": 1.0348153375676312,
      "grad_norm": 1.4488824605941772,
      "learning_rate": 4.9044281618349795e-05,
      "loss": 3.2469,
      "step": 3300
    },
    {
      "epoch": 1.050497922057555,
      "grad_norm": 1.5840378999710083,
      "learning_rate": 4.824784963364129e-05,
      "loss": 3.2651,
      "step": 3350
    },
    {
      "epoch": 1.066180506547479,
      "grad_norm": 1.4718937873840332,
      "learning_rate": 4.745141764893278e-05,
      "loss": 3.2652,
      "step": 3400
    },
    {
      "epoch": 1.081863091037403,
      "grad_norm": 1.728493571281433,
      "learning_rate": 4.6654985664224276e-05,
      "loss": 3.2574,
      "step": 3450
    },
    {
      "epoch": 1.097545675527327,
      "grad_norm": 1.5551892518997192,
      "learning_rate": 4.585855367951577e-05,
      "loss": 3.267,
      "step": 3500
    },
    {
      "epoch": 1.097545675527327,
      "eval_loss": 3.249533176422119,
      "eval_runtime": 82.5154,
      "eval_samples_per_second": 137.332,
      "eval_steps_per_second": 17.173,
      "step": 3500
    },
    {
      "epoch": 1.1132282600172507,
      "grad_norm": 1.5428080558776855,
      "learning_rate": 4.506212169480726e-05,
      "loss": 3.2414,
      "step": 3550
    },
    {
      "epoch": 1.1289108445071747,
      "grad_norm": 1.4538757801055908,
      "learning_rate": 4.4265689710098764e-05,
      "loss": 3.2515,
      "step": 3600
    },
    {
      "epoch": 1.1445934289970987,
      "grad_norm": 1.455668568611145,
      "learning_rate": 4.346925772539026e-05,
      "loss": 3.2598,
      "step": 3650
    },
    {
      "epoch": 1.1602760134870227,
      "grad_norm": 1.515450358390808,
      "learning_rate": 4.267282574068175e-05,
      "loss": 3.2551,
      "step": 3700
    },
    {
      "epoch": 1.1759585979769467,
      "grad_norm": 1.5753049850463867,
      "learning_rate": 4.1876393755973245e-05,
      "loss": 3.2377,
      "step": 3750
    },
    {
      "epoch": 1.1916411824668705,
      "grad_norm": 1.497134804725647,
      "learning_rate": 4.107996177126474e-05,
      "loss": 3.2386,
      "step": 3800
    },
    {
      "epoch": 1.2073237669567944,
      "grad_norm": 1.7458617687225342,
      "learning_rate": 4.028352978655623e-05,
      "loss": 3.2563,
      "step": 3850
    },
    {
      "epoch": 1.2230063514467184,
      "grad_norm": 1.5031627416610718,
      "learning_rate": 3.948709780184772e-05,
      "loss": 3.2457,
      "step": 3900
    },
    {
      "epoch": 1.2386889359366424,
      "grad_norm": 1.549509882926941,
      "learning_rate": 3.869066581713921e-05,
      "loss": 3.2379,
      "step": 3950
    },
    {
      "epoch": 1.2543715204265662,
      "grad_norm": 1.5994821786880493,
      "learning_rate": 3.789423383243071e-05,
      "loss": 3.2457,
      "step": 4000
    },
    {
      "epoch": 1.2543715204265662,
      "eval_loss": 3.245858669281006,
      "eval_runtime": 80.8347,
      "eval_samples_per_second": 140.187,
      "eval_steps_per_second": 17.53,
      "step": 4000
    },
    {
      "epoch": 1.2700541049164902,
      "grad_norm": 1.7681385278701782,
      "learning_rate": 3.709780184772221e-05,
      "loss": 3.2481,
      "step": 4050
    },
    {
      "epoch": 1.2857366894064142,
      "grad_norm": 1.5000982284545898,
      "learning_rate": 3.63013698630137e-05,
      "loss": 3.2458,
      "step": 4100
    },
    {
      "epoch": 1.3014192738963382,
      "grad_norm": 1.6816468238830566,
      "learning_rate": 3.5504937878305194e-05,
      "loss": 3.242,
      "step": 4150
    },
    {
      "epoch": 1.3171018583862621,
      "grad_norm": 1.5439798831939697,
      "learning_rate": 3.470850589359669e-05,
      "loss": 3.2505,
      "step": 4200
    },
    {
      "epoch": 1.332784442876186,
      "grad_norm": 1.4910502433776855,
      "learning_rate": 3.391207390888818e-05,
      "loss": 3.2399,
      "step": 4250
    },
    {
      "epoch": 1.34846702736611,
      "grad_norm": 1.7218462228775024,
      "learning_rate": 3.3115641924179675e-05,
      "loss": 3.2538,
      "step": 4300
    },
    {
      "epoch": 1.364149611856034,
      "grad_norm": 1.5715465545654297,
      "learning_rate": 3.2319209939471176e-05,
      "loss": 3.247,
      "step": 4350
    },
    {
      "epoch": 1.3798321963459579,
      "grad_norm": 1.700916051864624,
      "learning_rate": 3.152277795476267e-05,
      "loss": 3.254,
      "step": 4400
    },
    {
      "epoch": 1.3955147808358817,
      "grad_norm": 1.5702176094055176,
      "learning_rate": 3.072634597005416e-05,
      "loss": 3.2579,
      "step": 4450
    },
    {
      "epoch": 1.4111973653258056,
      "grad_norm": 1.7520142793655396,
      "learning_rate": 2.9929913985345654e-05,
      "loss": 3.2479,
      "step": 4500
    },
    {
      "epoch": 1.4111973653258056,
      "eval_loss": 3.242683172225952,
      "eval_runtime": 75.4326,
      "eval_samples_per_second": 150.227,
      "eval_steps_per_second": 18.785,
      "step": 4500
    },
    {
      "epoch": 1.4268799498157296,
      "grad_norm": 1.8340955972671509,
      "learning_rate": 2.9133482000637147e-05,
      "loss": 3.233,
      "step": 4550
    },
    {
      "epoch": 1.4425625343056536,
      "grad_norm": 1.7130566835403442,
      "learning_rate": 2.833705001592864e-05,
      "loss": 3.2535,
      "step": 4600
    },
    {
      "epoch": 1.4582451187955776,
      "grad_norm": 1.7473241090774536,
      "learning_rate": 2.7540618031220135e-05,
      "loss": 3.2468,
      "step": 4650
    },
    {
      "epoch": 1.4739277032855014,
      "grad_norm": 1.6918630599975586,
      "learning_rate": 2.674418604651163e-05,
      "loss": 3.2529,
      "step": 4700
    },
    {
      "epoch": 1.4896102877754254,
      "grad_norm": 1.71192467212677,
      "learning_rate": 2.5947754061803125e-05,
      "loss": 3.2499,
      "step": 4750
    },
    {
      "epoch": 1.5052928722653494,
      "grad_norm": 1.475574016571045,
      "learning_rate": 2.515132207709462e-05,
      "loss": 3.2509,
      "step": 4800
    },
    {
      "epoch": 1.5209754567552731,
      "grad_norm": 1.7269867658615112,
      "learning_rate": 2.4354890092386113e-05,
      "loss": 3.2414,
      "step": 4850
    },
    {
      "epoch": 1.5366580412451971,
      "grad_norm": 1.5403101444244385,
      "learning_rate": 2.3558458107677606e-05,
      "loss": 3.2525,
      "step": 4900
    },
    {
      "epoch": 1.552340625735121,
      "grad_norm": 1.6046867370605469,
      "learning_rate": 2.27620261229691e-05,
      "loss": 3.2402,
      "step": 4950
    },
    {
      "epoch": 1.568023210225045,
      "grad_norm": 1.603947401046753,
      "learning_rate": 2.1965594138260594e-05,
      "loss": 3.2395,
      "step": 5000
    },
    {
      "epoch": 1.568023210225045,
      "eval_loss": 3.2403690814971924,
      "eval_runtime": 75.1993,
      "eval_samples_per_second": 150.693,
      "eval_steps_per_second": 18.843,
      "step": 5000
    },
    {
      "epoch": 1.583705794714969,
      "grad_norm": 1.5867658853530884,
      "learning_rate": 2.1169162153552088e-05,
      "loss": 3.247,
      "step": 5050
    },
    {
      "epoch": 1.599388379204893,
      "grad_norm": 1.6359047889709473,
      "learning_rate": 2.037273016884358e-05,
      "loss": 3.2369,
      "step": 5100
    },
    {
      "epoch": 1.615070963694817,
      "grad_norm": 1.8419663906097412,
      "learning_rate": 1.9576298184135075e-05,
      "loss": 3.2423,
      "step": 5150
    },
    {
      "epoch": 1.6307535481847408,
      "grad_norm": 1.69842529296875,
      "learning_rate": 1.8779866199426572e-05,
      "loss": 3.2476,
      "step": 5200
    },
    {
      "epoch": 1.6464361326746648,
      "grad_norm": 1.605294942855835,
      "learning_rate": 1.7983434214718066e-05,
      "loss": 3.2493,
      "step": 5250
    },
    {
      "epoch": 1.6621187171645886,
      "grad_norm": 1.582280158996582,
      "learning_rate": 1.718700223000956e-05,
      "loss": 3.2394,
      "step": 5300
    },
    {
      "epoch": 1.6778013016545126,
      "grad_norm": 1.7263855934143066,
      "learning_rate": 1.639057024530105e-05,
      "loss": 3.2262,
      "step": 5350
    },
    {
      "epoch": 1.6934838861444366,
      "grad_norm": 1.6420979499816895,
      "learning_rate": 1.5594138260592547e-05,
      "loss": 3.2388,
      "step": 5400
    },
    {
      "epoch": 1.7091664706343606,
      "grad_norm": 1.8379055261611938,
      "learning_rate": 1.479770627588404e-05,
      "loss": 3.2448,
      "step": 5450
    },
    {
      "epoch": 1.7248490551242845,
      "grad_norm": 1.7877488136291504,
      "learning_rate": 1.4001274291175534e-05,
      "loss": 3.2396,
      "step": 5500
    },
    {
      "epoch": 1.7248490551242845,
      "eval_loss": 3.2384419441223145,
      "eval_runtime": 75.4022,
      "eval_samples_per_second": 150.287,
      "eval_steps_per_second": 18.793,
      "step": 5500
    },
    {
      "epoch": 1.7405316396142085,
      "grad_norm": 1.5742746591567993,
      "learning_rate": 1.3204842306467028e-05,
      "loss": 3.2406,
      "step": 5550
    },
    {
      "epoch": 1.7562142241041325,
      "grad_norm": 1.6590948104858398,
      "learning_rate": 1.2408410321758522e-05,
      "loss": 3.2423,
      "step": 5600
    },
    {
      "epoch": 1.7718968085940563,
      "grad_norm": 1.640398383140564,
      "learning_rate": 1.1611978337050017e-05,
      "loss": 3.2583,
      "step": 5650
    },
    {
      "epoch": 1.7875793930839803,
      "grad_norm": 1.8045361042022705,
      "learning_rate": 1.081554635234151e-05,
      "loss": 3.246,
      "step": 5700
    },
    {
      "epoch": 1.803261977573904,
      "grad_norm": 1.7478148937225342,
      "learning_rate": 1.0019114367633004e-05,
      "loss": 3.2483,
      "step": 5750
    },
    {
      "epoch": 1.818944562063828,
      "grad_norm": 1.618950366973877,
      "learning_rate": 9.222682382924498e-06,
      "loss": 3.2416,
      "step": 5800
    },
    {
      "epoch": 1.834627146553752,
      "grad_norm": 1.6943479776382446,
      "learning_rate": 8.426250398215993e-06,
      "loss": 3.2372,
      "step": 5850
    },
    {
      "epoch": 1.850309731043676,
      "grad_norm": 1.6796300411224365,
      "learning_rate": 7.629818413507487e-06,
      "loss": 3.2429,
      "step": 5900
    },
    {
      "epoch": 1.8659923155336,
      "grad_norm": 1.6725406646728516,
      "learning_rate": 6.833386428798981e-06,
      "loss": 3.2361,
      "step": 5950
    },
    {
      "epoch": 1.881674900023524,
      "grad_norm": 1.6117814779281616,
      "learning_rate": 6.036954444090475e-06,
      "loss": 3.2425,
      "step": 6000
    },
    {
      "epoch": 1.881674900023524,
      "eval_loss": 3.237149238586426,
      "eval_runtime": 75.6747,
      "eval_samples_per_second": 149.746,
      "eval_steps_per_second": 18.725,
      "step": 6000
    },
    {
      "epoch": 1.8973574845134478,
      "grad_norm": 1.531562328338623,
      "learning_rate": 5.240522459381969e-06,
      "loss": 3.2402,
      "step": 6050
    },
    {
      "epoch": 1.9130400690033718,
      "grad_norm": 1.6171923875808716,
      "learning_rate": 4.4440904746734635e-06,
      "loss": 3.24,
      "step": 6100
    },
    {
      "epoch": 1.9287226534932957,
      "grad_norm": 1.9494956731796265,
      "learning_rate": 3.647658489964957e-06,
      "loss": 3.2417,
      "step": 6150
    },
    {
      "epoch": 1.9444052379832195,
      "grad_norm": 1.6676418781280518,
      "learning_rate": 2.8512265052564513e-06,
      "loss": 3.2427,
      "step": 6200
    },
    {
      "epoch": 1.9600878224731435,
      "grad_norm": 1.662553310394287,
      "learning_rate": 2.054794520547945e-06,
      "loss": 3.2414,
      "step": 6250
    },
    {
      "epoch": 1.9757704069630675,
      "grad_norm": 1.6463679075241089,
      "learning_rate": 1.2583625358394393e-06,
      "loss": 3.2396,
      "step": 6300
    },
    {
      "epoch": 1.9914529914529915,
      "grad_norm": 1.6735647916793823,
      "learning_rate": 4.6193055113093345e-07,
      "loss": 3.243,
      "step": 6350
    }
  ],
  "logging_steps": 50,
  "max_steps": 6378,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 2,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 2.812417897660416e+16,
  "train_batch_size": 8,
  "trial_name": null,
  "trial_params": null
}
