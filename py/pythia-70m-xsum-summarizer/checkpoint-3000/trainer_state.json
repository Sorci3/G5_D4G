{
  "best_global_step": 3000,
  "best_metric": 2.9530112743377686,
  "best_model_checkpoint": "./pythia-70m-xsum-summarizer\\checkpoint-3000",
  "epoch": 0.9409550693954364,
  "eval_steps": 500,
  "global_step": 3000,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.01568258448992394,
      "grad_norm": 3.833181381225586,
      "learning_rate": 9.8e-05,
      "loss": 4.02,
      "step": 50
    },
    {
      "epoch": 0.03136516897984788,
      "grad_norm": 2.7710986137390137,
      "learning_rate": 0.00019800000000000002,
      "loss": 3.3396,
      "step": 100
    },
    {
      "epoch": 0.047047753469771816,
      "grad_norm": 2.5118908882141113,
      "learning_rate": 0.0001989648251822119,
      "loss": 3.1055,
      "step": 150
    },
    {
      "epoch": 0.06273033795969576,
      "grad_norm": 2.277897834777832,
      "learning_rate": 0.00019790852434773423,
      "loss": 3.0671,
      "step": 200
    },
    {
      "epoch": 0.0784129224496197,
      "grad_norm": 1.995082974433899,
      "learning_rate": 0.0001968522235132566,
      "loss": 3.0558,
      "step": 250
    },
    {
      "epoch": 0.09409550693954363,
      "grad_norm": 1.7604159116744995,
      "learning_rate": 0.00019579592267877894,
      "loss": 3.0333,
      "step": 300
    },
    {
      "epoch": 0.10977809142946758,
      "grad_norm": 1.7713491916656494,
      "learning_rate": 0.00019473962184430126,
      "loss": 3.0462,
      "step": 350
    },
    {
      "epoch": 0.12546067591939153,
      "grad_norm": 1.8713388442993164,
      "learning_rate": 0.00019368332100982362,
      "loss": 3.035,
      "step": 400
    },
    {
      "epoch": 0.14114326040931546,
      "grad_norm": 1.73073410987854,
      "learning_rate": 0.00019262702017534594,
      "loss": 3.0245,
      "step": 450
    },
    {
      "epoch": 0.1568258448992394,
      "grad_norm": 1.607773780822754,
      "learning_rate": 0.0001915707193408683,
      "loss": 3.0346,
      "step": 500
    },
    {
      "epoch": 0.1568258448992394,
      "eval_loss": 3.0135490894317627,
      "eval_runtime": 46.4716,
      "eval_samples_per_second": 243.848,
      "eval_steps_per_second": 30.492,
      "step": 500
    },
    {
      "epoch": 0.17250842938916333,
      "grad_norm": 1.966647744178772,
      "learning_rate": 0.00019051441850639062,
      "loss": 3.0221,
      "step": 550
    },
    {
      "epoch": 0.18819101387908727,
      "grad_norm": 1.6319724321365356,
      "learning_rate": 0.00018945811767191297,
      "loss": 3.0203,
      "step": 600
    },
    {
      "epoch": 0.2038735983690112,
      "grad_norm": 1.938615083694458,
      "learning_rate": 0.00018840181683743533,
      "loss": 3.0132,
      "step": 650
    },
    {
      "epoch": 0.21955618285893516,
      "grad_norm": 1.6289666891098022,
      "learning_rate": 0.00018734551600295765,
      "loss": 3.0072,
      "step": 700
    },
    {
      "epoch": 0.2352387673488591,
      "grad_norm": 1.390468716621399,
      "learning_rate": 0.00018628921516848,
      "loss": 3.0164,
      "step": 750
    },
    {
      "epoch": 0.25092135183878306,
      "grad_norm": 1.8141419887542725,
      "learning_rate": 0.00018523291433400233,
      "loss": 3.0059,
      "step": 800
    },
    {
      "epoch": 0.266603936328707,
      "grad_norm": 1.5383907556533813,
      "learning_rate": 0.00018417661349952465,
      "loss": 2.9813,
      "step": 850
    },
    {
      "epoch": 0.2822865208186309,
      "grad_norm": 1.6310404539108276,
      "learning_rate": 0.000183120312665047,
      "loss": 2.9947,
      "step": 900
    },
    {
      "epoch": 0.29796910530855486,
      "grad_norm": 1.4976071119308472,
      "learning_rate": 0.00018206401183056936,
      "loss": 2.9931,
      "step": 950
    },
    {
      "epoch": 0.3136516897984788,
      "grad_norm": 1.3926053047180176,
      "learning_rate": 0.0001810077109960917,
      "loss": 3.0005,
      "step": 1000
    },
    {
      "epoch": 0.3136516897984788,
      "eval_loss": 2.9893016815185547,
      "eval_runtime": 46.6213,
      "eval_samples_per_second": 243.065,
      "eval_steps_per_second": 30.394,
      "step": 1000
    },
    {
      "epoch": 0.32933427428840273,
      "grad_norm": 1.8714981079101562,
      "learning_rate": 0.00017995141016161404,
      "loss": 2.9844,
      "step": 1050
    },
    {
      "epoch": 0.34501685877832666,
      "grad_norm": 1.6839807033538818,
      "learning_rate": 0.0001788951093271364,
      "loss": 2.9841,
      "step": 1100
    },
    {
      "epoch": 0.3606994432682506,
      "grad_norm": 1.5096240043640137,
      "learning_rate": 0.0001778388084926587,
      "loss": 2.9955,
      "step": 1150
    },
    {
      "epoch": 0.37638202775817453,
      "grad_norm": 1.4713188409805298,
      "learning_rate": 0.00017678250765818104,
      "loss": 2.9864,
      "step": 1200
    },
    {
      "epoch": 0.39206461224809847,
      "grad_norm": 1.6477006673812866,
      "learning_rate": 0.0001757262068237034,
      "loss": 2.9817,
      "step": 1250
    },
    {
      "epoch": 0.4077471967380224,
      "grad_norm": 1.7117180824279785,
      "learning_rate": 0.00017466990598922574,
      "loss": 2.9868,
      "step": 1300
    },
    {
      "epoch": 0.4234297812279464,
      "grad_norm": 1.625845193862915,
      "learning_rate": 0.00017361360515474807,
      "loss": 2.9866,
      "step": 1350
    },
    {
      "epoch": 0.4391123657178703,
      "grad_norm": 1.7361077070236206,
      "learning_rate": 0.00017255730432027042,
      "loss": 2.9715,
      "step": 1400
    },
    {
      "epoch": 0.45479495020779426,
      "grad_norm": 1.4359303712844849,
      "learning_rate": 0.00017150100348579277,
      "loss": 2.9907,
      "step": 1450
    },
    {
      "epoch": 0.4704775346977182,
      "grad_norm": 1.5308500528335571,
      "learning_rate": 0.00017044470265131513,
      "loss": 2.9858,
      "step": 1500
    },
    {
      "epoch": 0.4704775346977182,
      "eval_loss": 2.9749133586883545,
      "eval_runtime": 46.5612,
      "eval_samples_per_second": 243.378,
      "eval_steps_per_second": 30.433,
      "step": 1500
    },
    {
      "epoch": 0.4861601191876421,
      "grad_norm": 1.4840519428253174,
      "learning_rate": 0.00016938840181683745,
      "loss": 2.9687,
      "step": 1550
    },
    {
      "epoch": 0.5018427036775661,
      "grad_norm": 2.3720390796661377,
      "learning_rate": 0.00016833210098235978,
      "loss": 2.9785,
      "step": 1600
    },
    {
      "epoch": 0.51752528816749,
      "grad_norm": 1.663994312286377,
      "learning_rate": 0.00016727580014788213,
      "loss": 2.9599,
      "step": 1650
    },
    {
      "epoch": 0.533207872657414,
      "grad_norm": 1.4365259408950806,
      "learning_rate": 0.00016621949931340445,
      "loss": 2.982,
      "step": 1700
    },
    {
      "epoch": 0.5488904571473379,
      "grad_norm": 1.6500166654586792,
      "learning_rate": 0.0001651631984789268,
      "loss": 2.9666,
      "step": 1750
    },
    {
      "epoch": 0.5645730416372619,
      "grad_norm": 1.490764856338501,
      "learning_rate": 0.00016410689764444916,
      "loss": 2.9673,
      "step": 1800
    },
    {
      "epoch": 0.5802556261271857,
      "grad_norm": 1.5859612226486206,
      "learning_rate": 0.00016305059680997148,
      "loss": 2.9658,
      "step": 1850
    },
    {
      "epoch": 0.5959382106171097,
      "grad_norm": 1.4504107236862183,
      "learning_rate": 0.00016199429597549384,
      "loss": 2.9643,
      "step": 1900
    },
    {
      "epoch": 0.6116207951070336,
      "grad_norm": 1.736838698387146,
      "learning_rate": 0.00016093799514101616,
      "loss": 2.9698,
      "step": 1950
    },
    {
      "epoch": 0.6273033795969576,
      "grad_norm": 1.5479280948638916,
      "learning_rate": 0.00015988169430653851,
      "loss": 2.9756,
      "step": 2000
    },
    {
      "epoch": 0.6273033795969576,
      "eval_loss": 2.967554807662964,
      "eval_runtime": 46.5694,
      "eval_samples_per_second": 243.336,
      "eval_steps_per_second": 30.428,
      "step": 2000
    },
    {
      "epoch": 0.6429859640868815,
      "grad_norm": 1.6957513093948364,
      "learning_rate": 0.00015882539347206084,
      "loss": 2.9765,
      "step": 2050
    },
    {
      "epoch": 0.6586685485768055,
      "grad_norm": 1.9758931398391724,
      "learning_rate": 0.0001577690926375832,
      "loss": 2.9739,
      "step": 2100
    },
    {
      "epoch": 0.6743511330667294,
      "grad_norm": 1.9542165994644165,
      "learning_rate": 0.00015671279180310554,
      "loss": 2.972,
      "step": 2150
    },
    {
      "epoch": 0.6900337175566533,
      "grad_norm": 1.4416577816009521,
      "learning_rate": 0.00015565649096862787,
      "loss": 2.9665,
      "step": 2200
    },
    {
      "epoch": 0.7057163020465773,
      "grad_norm": 1.3789575099945068,
      "learning_rate": 0.00015460019013415022,
      "loss": 2.9631,
      "step": 2250
    },
    {
      "epoch": 0.7213988865365012,
      "grad_norm": 1.5378917455673218,
      "learning_rate": 0.00015354388929967255,
      "loss": 2.9753,
      "step": 2300
    },
    {
      "epoch": 0.7370814710264252,
      "grad_norm": 1.6364811658859253,
      "learning_rate": 0.00015248758846519487,
      "loss": 2.9666,
      "step": 2350
    },
    {
      "epoch": 0.7527640555163491,
      "grad_norm": 1.326087474822998,
      "learning_rate": 0.00015143128763071723,
      "loss": 2.9663,
      "step": 2400
    },
    {
      "epoch": 0.768446640006273,
      "grad_norm": 1.4928799867630005,
      "learning_rate": 0.00015037498679623958,
      "loss": 2.9806,
      "step": 2450
    },
    {
      "epoch": 0.7841292244961969,
      "grad_norm": 1.6634109020233154,
      "learning_rate": 0.0001493186859617619,
      "loss": 2.9585,
      "step": 2500
    },
    {
      "epoch": 0.7841292244961969,
      "eval_loss": 2.9598798751831055,
      "eval_runtime": 46.7463,
      "eval_samples_per_second": 242.415,
      "eval_steps_per_second": 30.313,
      "step": 2500
    },
    {
      "epoch": 0.7998118089861209,
      "grad_norm": 1.856436014175415,
      "learning_rate": 0.00014826238512728426,
      "loss": 2.9662,
      "step": 2550
    },
    {
      "epoch": 0.8154943934760448,
      "grad_norm": 1.7303508520126343,
      "learning_rate": 0.0001472060842928066,
      "loss": 2.963,
      "step": 2600
    },
    {
      "epoch": 0.8311769779659688,
      "grad_norm": 1.5605945587158203,
      "learning_rate": 0.00014614978345832896,
      "loss": 2.9653,
      "step": 2650
    },
    {
      "epoch": 0.8468595624558928,
      "grad_norm": 1.703322410583496,
      "learning_rate": 0.00014509348262385129,
      "loss": 2.9542,
      "step": 2700
    },
    {
      "epoch": 0.8625421469458167,
      "grad_norm": 1.8575642108917236,
      "learning_rate": 0.0001440371817893736,
      "loss": 2.9629,
      "step": 2750
    },
    {
      "epoch": 0.8782247314357406,
      "grad_norm": 1.6529910564422607,
      "learning_rate": 0.00014298088095489596,
      "loss": 2.9639,
      "step": 2800
    },
    {
      "epoch": 0.8939073159256645,
      "grad_norm": 2.0566461086273193,
      "learning_rate": 0.0001419245801204183,
      "loss": 2.9565,
      "step": 2850
    },
    {
      "epoch": 0.9095899004155885,
      "grad_norm": 1.5267177820205688,
      "learning_rate": 0.00014086827928594064,
      "loss": 2.9552,
      "step": 2900
    },
    {
      "epoch": 0.9252724849055124,
      "grad_norm": 1.4600589275360107,
      "learning_rate": 0.000139811978451463,
      "loss": 2.9646,
      "step": 2950
    },
    {
      "epoch": 0.9409550693954364,
      "grad_norm": 1.4252005815505981,
      "learning_rate": 0.00013875567761698532,
      "loss": 2.9511,
      "step": 3000
    },
    {
      "epoch": 0.9409550693954364,
      "eval_loss": 2.9530112743377686,
      "eval_runtime": 46.7743,
      "eval_samples_per_second": 242.27,
      "eval_steps_per_second": 30.294,
      "step": 3000
    }
  ],
  "logging_steps": 50,
  "max_steps": 9567,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 3,
  "save_steps": 1000,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 1.3231988932608e+16,
  "train_batch_size": 8,
  "trial_name": null,
  "trial_params": null
}
