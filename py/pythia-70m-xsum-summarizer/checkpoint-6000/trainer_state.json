{
  "best_global_step": 6000,
  "best_metric": 2.9313199520111084,
  "best_model_checkpoint": "./pythia-70m-xsum-summarizer\\checkpoint-6000",
  "epoch": 1.881674900023524,
  "eval_steps": 500,
  "global_step": 6000,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.01568258448992394,
      "grad_norm": 3.833181381225586,
      "learning_rate": 9.8e-05,
      "loss": 4.02,
      "step": 50
    },
    {
      "epoch": 0.03136516897984788,
      "grad_norm": 2.7710986137390137,
      "learning_rate": 0.00019800000000000002,
      "loss": 3.3396,
      "step": 100
    },
    {
      "epoch": 0.047047753469771816,
      "grad_norm": 2.5118908882141113,
      "learning_rate": 0.0001989648251822119,
      "loss": 3.1055,
      "step": 150
    },
    {
      "epoch": 0.06273033795969576,
      "grad_norm": 2.277897834777832,
      "learning_rate": 0.00019790852434773423,
      "loss": 3.0671,
      "step": 200
    },
    {
      "epoch": 0.0784129224496197,
      "grad_norm": 1.995082974433899,
      "learning_rate": 0.0001968522235132566,
      "loss": 3.0558,
      "step": 250
    },
    {
      "epoch": 0.09409550693954363,
      "grad_norm": 1.7604159116744995,
      "learning_rate": 0.00019579592267877894,
      "loss": 3.0333,
      "step": 300
    },
    {
      "epoch": 0.10977809142946758,
      "grad_norm": 1.7713491916656494,
      "learning_rate": 0.00019473962184430126,
      "loss": 3.0462,
      "step": 350
    },
    {
      "epoch": 0.12546067591939153,
      "grad_norm": 1.8713388442993164,
      "learning_rate": 0.00019368332100982362,
      "loss": 3.035,
      "step": 400
    },
    {
      "epoch": 0.14114326040931546,
      "grad_norm": 1.73073410987854,
      "learning_rate": 0.00019262702017534594,
      "loss": 3.0245,
      "step": 450
    },
    {
      "epoch": 0.1568258448992394,
      "grad_norm": 1.607773780822754,
      "learning_rate": 0.0001915707193408683,
      "loss": 3.0346,
      "step": 500
    },
    {
      "epoch": 0.1568258448992394,
      "eval_loss": 3.0135490894317627,
      "eval_runtime": 46.4716,
      "eval_samples_per_second": 243.848,
      "eval_steps_per_second": 30.492,
      "step": 500
    },
    {
      "epoch": 0.17250842938916333,
      "grad_norm": 1.966647744178772,
      "learning_rate": 0.00019051441850639062,
      "loss": 3.0221,
      "step": 550
    },
    {
      "epoch": 0.18819101387908727,
      "grad_norm": 1.6319724321365356,
      "learning_rate": 0.00018945811767191297,
      "loss": 3.0203,
      "step": 600
    },
    {
      "epoch": 0.2038735983690112,
      "grad_norm": 1.938615083694458,
      "learning_rate": 0.00018840181683743533,
      "loss": 3.0132,
      "step": 650
    },
    {
      "epoch": 0.21955618285893516,
      "grad_norm": 1.6289666891098022,
      "learning_rate": 0.00018734551600295765,
      "loss": 3.0072,
      "step": 700
    },
    {
      "epoch": 0.2352387673488591,
      "grad_norm": 1.390468716621399,
      "learning_rate": 0.00018628921516848,
      "loss": 3.0164,
      "step": 750
    },
    {
      "epoch": 0.25092135183878306,
      "grad_norm": 1.8141419887542725,
      "learning_rate": 0.00018523291433400233,
      "loss": 3.0059,
      "step": 800
    },
    {
      "epoch": 0.266603936328707,
      "grad_norm": 1.5383907556533813,
      "learning_rate": 0.00018417661349952465,
      "loss": 2.9813,
      "step": 850
    },
    {
      "epoch": 0.2822865208186309,
      "grad_norm": 1.6310404539108276,
      "learning_rate": 0.000183120312665047,
      "loss": 2.9947,
      "step": 900
    },
    {
      "epoch": 0.29796910530855486,
      "grad_norm": 1.4976071119308472,
      "learning_rate": 0.00018206401183056936,
      "loss": 2.9931,
      "step": 950
    },
    {
      "epoch": 0.3136516897984788,
      "grad_norm": 1.3926053047180176,
      "learning_rate": 0.0001810077109960917,
      "loss": 3.0005,
      "step": 1000
    },
    {
      "epoch": 0.3136516897984788,
      "eval_loss": 2.9893016815185547,
      "eval_runtime": 46.6213,
      "eval_samples_per_second": 243.065,
      "eval_steps_per_second": 30.394,
      "step": 1000
    },
    {
      "epoch": 0.32933427428840273,
      "grad_norm": 1.8714981079101562,
      "learning_rate": 0.00017995141016161404,
      "loss": 2.9844,
      "step": 1050
    },
    {
      "epoch": 0.34501685877832666,
      "grad_norm": 1.6839807033538818,
      "learning_rate": 0.0001788951093271364,
      "loss": 2.9841,
      "step": 1100
    },
    {
      "epoch": 0.3606994432682506,
      "grad_norm": 1.5096240043640137,
      "learning_rate": 0.0001778388084926587,
      "loss": 2.9955,
      "step": 1150
    },
    {
      "epoch": 0.37638202775817453,
      "grad_norm": 1.4713188409805298,
      "learning_rate": 0.00017678250765818104,
      "loss": 2.9864,
      "step": 1200
    },
    {
      "epoch": 0.39206461224809847,
      "grad_norm": 1.6477006673812866,
      "learning_rate": 0.0001757262068237034,
      "loss": 2.9817,
      "step": 1250
    },
    {
      "epoch": 0.4077471967380224,
      "grad_norm": 1.7117180824279785,
      "learning_rate": 0.00017466990598922574,
      "loss": 2.9868,
      "step": 1300
    },
    {
      "epoch": 0.4234297812279464,
      "grad_norm": 1.625845193862915,
      "learning_rate": 0.00017361360515474807,
      "loss": 2.9866,
      "step": 1350
    },
    {
      "epoch": 0.4391123657178703,
      "grad_norm": 1.7361077070236206,
      "learning_rate": 0.00017255730432027042,
      "loss": 2.9715,
      "step": 1400
    },
    {
      "epoch": 0.45479495020779426,
      "grad_norm": 1.4359303712844849,
      "learning_rate": 0.00017150100348579277,
      "loss": 2.9907,
      "step": 1450
    },
    {
      "epoch": 0.4704775346977182,
      "grad_norm": 1.5308500528335571,
      "learning_rate": 0.00017044470265131513,
      "loss": 2.9858,
      "step": 1500
    },
    {
      "epoch": 0.4704775346977182,
      "eval_loss": 2.9749133586883545,
      "eval_runtime": 46.5612,
      "eval_samples_per_second": 243.378,
      "eval_steps_per_second": 30.433,
      "step": 1500
    },
    {
      "epoch": 0.4861601191876421,
      "grad_norm": 1.4840519428253174,
      "learning_rate": 0.00016938840181683745,
      "loss": 2.9687,
      "step": 1550
    },
    {
      "epoch": 0.5018427036775661,
      "grad_norm": 2.3720390796661377,
      "learning_rate": 0.00016833210098235978,
      "loss": 2.9785,
      "step": 1600
    },
    {
      "epoch": 0.51752528816749,
      "grad_norm": 1.663994312286377,
      "learning_rate": 0.00016727580014788213,
      "loss": 2.9599,
      "step": 1650
    },
    {
      "epoch": 0.533207872657414,
      "grad_norm": 1.4365259408950806,
      "learning_rate": 0.00016621949931340445,
      "loss": 2.982,
      "step": 1700
    },
    {
      "epoch": 0.5488904571473379,
      "grad_norm": 1.6500166654586792,
      "learning_rate": 0.0001651631984789268,
      "loss": 2.9666,
      "step": 1750
    },
    {
      "epoch": 0.5645730416372619,
      "grad_norm": 1.490764856338501,
      "learning_rate": 0.00016410689764444916,
      "loss": 2.9673,
      "step": 1800
    },
    {
      "epoch": 0.5802556261271857,
      "grad_norm": 1.5859612226486206,
      "learning_rate": 0.00016305059680997148,
      "loss": 2.9658,
      "step": 1850
    },
    {
      "epoch": 0.5959382106171097,
      "grad_norm": 1.4504107236862183,
      "learning_rate": 0.00016199429597549384,
      "loss": 2.9643,
      "step": 1900
    },
    {
      "epoch": 0.6116207951070336,
      "grad_norm": 1.736838698387146,
      "learning_rate": 0.00016093799514101616,
      "loss": 2.9698,
      "step": 1950
    },
    {
      "epoch": 0.6273033795969576,
      "grad_norm": 1.5479280948638916,
      "learning_rate": 0.00015988169430653851,
      "loss": 2.9756,
      "step": 2000
    },
    {
      "epoch": 0.6273033795969576,
      "eval_loss": 2.967554807662964,
      "eval_runtime": 46.5694,
      "eval_samples_per_second": 243.336,
      "eval_steps_per_second": 30.428,
      "step": 2000
    },
    {
      "epoch": 0.6429859640868815,
      "grad_norm": 1.6957513093948364,
      "learning_rate": 0.00015882539347206084,
      "loss": 2.9765,
      "step": 2050
    },
    {
      "epoch": 0.6586685485768055,
      "grad_norm": 1.9758931398391724,
      "learning_rate": 0.0001577690926375832,
      "loss": 2.9739,
      "step": 2100
    },
    {
      "epoch": 0.6743511330667294,
      "grad_norm": 1.9542165994644165,
      "learning_rate": 0.00015671279180310554,
      "loss": 2.972,
      "step": 2150
    },
    {
      "epoch": 0.6900337175566533,
      "grad_norm": 1.4416577816009521,
      "learning_rate": 0.00015565649096862787,
      "loss": 2.9665,
      "step": 2200
    },
    {
      "epoch": 0.7057163020465773,
      "grad_norm": 1.3789575099945068,
      "learning_rate": 0.00015460019013415022,
      "loss": 2.9631,
      "step": 2250
    },
    {
      "epoch": 0.7213988865365012,
      "grad_norm": 1.5378917455673218,
      "learning_rate": 0.00015354388929967255,
      "loss": 2.9753,
      "step": 2300
    },
    {
      "epoch": 0.7370814710264252,
      "grad_norm": 1.6364811658859253,
      "learning_rate": 0.00015248758846519487,
      "loss": 2.9666,
      "step": 2350
    },
    {
      "epoch": 0.7527640555163491,
      "grad_norm": 1.326087474822998,
      "learning_rate": 0.00015143128763071723,
      "loss": 2.9663,
      "step": 2400
    },
    {
      "epoch": 0.768446640006273,
      "grad_norm": 1.4928799867630005,
      "learning_rate": 0.00015037498679623958,
      "loss": 2.9806,
      "step": 2450
    },
    {
      "epoch": 0.7841292244961969,
      "grad_norm": 1.6634109020233154,
      "learning_rate": 0.0001493186859617619,
      "loss": 2.9585,
      "step": 2500
    },
    {
      "epoch": 0.7841292244961969,
      "eval_loss": 2.9598798751831055,
      "eval_runtime": 46.7463,
      "eval_samples_per_second": 242.415,
      "eval_steps_per_second": 30.313,
      "step": 2500
    },
    {
      "epoch": 0.7998118089861209,
      "grad_norm": 1.856436014175415,
      "learning_rate": 0.00014826238512728426,
      "loss": 2.9662,
      "step": 2550
    },
    {
      "epoch": 0.8154943934760448,
      "grad_norm": 1.7303508520126343,
      "learning_rate": 0.0001472060842928066,
      "loss": 2.963,
      "step": 2600
    },
    {
      "epoch": 0.8311769779659688,
      "grad_norm": 1.5605945587158203,
      "learning_rate": 0.00014614978345832896,
      "loss": 2.9653,
      "step": 2650
    },
    {
      "epoch": 0.8468595624558928,
      "grad_norm": 1.703322410583496,
      "learning_rate": 0.00014509348262385129,
      "loss": 2.9542,
      "step": 2700
    },
    {
      "epoch": 0.8625421469458167,
      "grad_norm": 1.8575642108917236,
      "learning_rate": 0.0001440371817893736,
      "loss": 2.9629,
      "step": 2750
    },
    {
      "epoch": 0.8782247314357406,
      "grad_norm": 1.6529910564422607,
      "learning_rate": 0.00014298088095489596,
      "loss": 2.9639,
      "step": 2800
    },
    {
      "epoch": 0.8939073159256645,
      "grad_norm": 2.0566461086273193,
      "learning_rate": 0.0001419245801204183,
      "loss": 2.9565,
      "step": 2850
    },
    {
      "epoch": 0.9095899004155885,
      "grad_norm": 1.5267177820205688,
      "learning_rate": 0.00014086827928594064,
      "loss": 2.9552,
      "step": 2900
    },
    {
      "epoch": 0.9252724849055124,
      "grad_norm": 1.4600589275360107,
      "learning_rate": 0.000139811978451463,
      "loss": 2.9646,
      "step": 2950
    },
    {
      "epoch": 0.9409550693954364,
      "grad_norm": 1.4252005815505981,
      "learning_rate": 0.00013875567761698532,
      "loss": 2.9511,
      "step": 3000
    },
    {
      "epoch": 0.9409550693954364,
      "eval_loss": 2.9530112743377686,
      "eval_runtime": 46.7743,
      "eval_samples_per_second": 242.27,
      "eval_steps_per_second": 30.294,
      "step": 3000
    },
    {
      "epoch": 0.9566376538853603,
      "grad_norm": 1.533394694328308,
      "learning_rate": 0.00013769937678250767,
      "loss": 2.9515,
      "step": 3050
    },
    {
      "epoch": 0.9723202383752843,
      "grad_norm": 1.456629753112793,
      "learning_rate": 0.00013664307594803,
      "loss": 2.9531,
      "step": 3100
    },
    {
      "epoch": 0.9880028228652082,
      "grad_norm": 1.5567609071731567,
      "learning_rate": 0.00013558677511355235,
      "loss": 2.9566,
      "step": 3150
    },
    {
      "epoch": 1.0034501685877832,
      "grad_norm": 1.4663406610488892,
      "learning_rate": 0.00013453047427907467,
      "loss": 2.961,
      "step": 3200
    },
    {
      "epoch": 1.0191327530777072,
      "grad_norm": 2.0034031867980957,
      "learning_rate": 0.00013347417344459703,
      "loss": 2.9512,
      "step": 3250
    },
    {
      "epoch": 1.0348153375676312,
      "grad_norm": 1.5138664245605469,
      "learning_rate": 0.00013241787261011938,
      "loss": 2.9487,
      "step": 3300
    },
    {
      "epoch": 1.050497922057555,
      "grad_norm": 1.5865230560302734,
      "learning_rate": 0.0001313615717756417,
      "loss": 2.9619,
      "step": 3350
    },
    {
      "epoch": 1.066180506547479,
      "grad_norm": 1.8753890991210938,
      "learning_rate": 0.00013030527094116406,
      "loss": 2.9604,
      "step": 3400
    },
    {
      "epoch": 1.081863091037403,
      "grad_norm": 1.6500777006149292,
      "learning_rate": 0.0001292489701066864,
      "loss": 2.9565,
      "step": 3450
    },
    {
      "epoch": 1.097545675527327,
      "grad_norm": 1.5197460651397705,
      "learning_rate": 0.00012819266927220873,
      "loss": 2.9685,
      "step": 3500
    },
    {
      "epoch": 1.097545675527327,
      "eval_loss": 2.94925594329834,
      "eval_runtime": 46.723,
      "eval_samples_per_second": 242.536,
      "eval_steps_per_second": 30.328,
      "step": 3500
    },
    {
      "epoch": 1.1132282600172507,
      "grad_norm": 1.326562523841858,
      "learning_rate": 0.00012713636843773106,
      "loss": 2.9401,
      "step": 3550
    },
    {
      "epoch": 1.1289108445071747,
      "grad_norm": 1.6324068307876587,
      "learning_rate": 0.0001260800676032534,
      "loss": 2.9506,
      "step": 3600
    },
    {
      "epoch": 1.1445934289970987,
      "grad_norm": 1.5953855514526367,
      "learning_rate": 0.00012502376676877576,
      "loss": 2.958,
      "step": 3650
    },
    {
      "epoch": 1.1602760134870227,
      "grad_norm": 1.581068992614746,
      "learning_rate": 0.0001239674659342981,
      "loss": 2.9513,
      "step": 3700
    },
    {
      "epoch": 1.1759585979769467,
      "grad_norm": 1.6463632583618164,
      "learning_rate": 0.00012291116509982044,
      "loss": 2.9382,
      "step": 3750
    },
    {
      "epoch": 1.1916411824668705,
      "grad_norm": 1.6897501945495605,
      "learning_rate": 0.00012185486426534278,
      "loss": 2.9393,
      "step": 3800
    },
    {
      "epoch": 1.2073237669567944,
      "grad_norm": 1.6552120447158813,
      "learning_rate": 0.0001207985634308651,
      "loss": 2.9567,
      "step": 3850
    },
    {
      "epoch": 1.2230063514467184,
      "grad_norm": 1.4421063661575317,
      "learning_rate": 0.00011974226259638746,
      "loss": 2.9419,
      "step": 3900
    },
    {
      "epoch": 1.2386889359366424,
      "grad_norm": 1.5042452812194824,
      "learning_rate": 0.0001186859617619098,
      "loss": 2.9385,
      "step": 3950
    },
    {
      "epoch": 1.2543715204265662,
      "grad_norm": 1.595487117767334,
      "learning_rate": 0.00011762966092743212,
      "loss": 2.9408,
      "step": 4000
    },
    {
      "epoch": 1.2543715204265662,
      "eval_loss": 2.943643808364868,
      "eval_runtime": 47.0078,
      "eval_samples_per_second": 241.066,
      "eval_steps_per_second": 30.144,
      "step": 4000
    },
    {
      "epoch": 1.2700541049164902,
      "grad_norm": 1.6569511890411377,
      "learning_rate": 0.00011657336009295447,
      "loss": 2.9441,
      "step": 4050
    },
    {
      "epoch": 1.2857366894064142,
      "grad_norm": 1.6077288389205933,
      "learning_rate": 0.00011551705925847683,
      "loss": 2.9453,
      "step": 4100
    },
    {
      "epoch": 1.3014192738963382,
      "grad_norm": 1.6392207145690918,
      "learning_rate": 0.00011446075842399917,
      "loss": 2.9398,
      "step": 4150
    },
    {
      "epoch": 1.3171018583862621,
      "grad_norm": 1.7775018215179443,
      "learning_rate": 0.00011340445758952149,
      "loss": 2.9489,
      "step": 4200
    },
    {
      "epoch": 1.332784442876186,
      "grad_norm": 1.7078347206115723,
      "learning_rate": 0.00011234815675504384,
      "loss": 2.9369,
      "step": 4250
    },
    {
      "epoch": 1.34846702736611,
      "grad_norm": 1.5459624528884888,
      "learning_rate": 0.0001112918559205662,
      "loss": 2.9512,
      "step": 4300
    },
    {
      "epoch": 1.364149611856034,
      "grad_norm": 1.5739518404006958,
      "learning_rate": 0.00011023555508608852,
      "loss": 2.943,
      "step": 4350
    },
    {
      "epoch": 1.3798321963459579,
      "grad_norm": 1.5818517208099365,
      "learning_rate": 0.00010917925425161086,
      "loss": 2.9484,
      "step": 4400
    },
    {
      "epoch": 1.3955147808358817,
      "grad_norm": 1.6248295307159424,
      "learning_rate": 0.00010812295341713321,
      "loss": 2.954,
      "step": 4450
    },
    {
      "epoch": 1.4111973653258056,
      "grad_norm": 1.5167756080627441,
      "learning_rate": 0.00010706665258265554,
      "loss": 2.9449,
      "step": 4500
    },
    {
      "epoch": 1.4111973653258056,
      "eval_loss": 2.939418077468872,
      "eval_runtime": 46.5348,
      "eval_samples_per_second": 243.517,
      "eval_steps_per_second": 30.45,
      "step": 4500
    },
    {
      "epoch": 1.4268799498157296,
      "grad_norm": 1.656449317932129,
      "learning_rate": 0.00010601035174817788,
      "loss": 2.9297,
      "step": 4550
    },
    {
      "epoch": 1.4425625343056536,
      "grad_norm": 1.594496250152588,
      "learning_rate": 0.00010495405091370023,
      "loss": 2.9512,
      "step": 4600
    },
    {
      "epoch": 1.4582451187955776,
      "grad_norm": 1.4972716569900513,
      "learning_rate": 0.00010389775007922258,
      "loss": 2.9447,
      "step": 4650
    },
    {
      "epoch": 1.4739277032855014,
      "grad_norm": 1.5887229442596436,
      "learning_rate": 0.0001028414492447449,
      "loss": 2.9496,
      "step": 4700
    },
    {
      "epoch": 1.4896102877754254,
      "grad_norm": 1.473965048789978,
      "learning_rate": 0.00010178514841026725,
      "loss": 2.9462,
      "step": 4750
    },
    {
      "epoch": 1.5052928722653494,
      "grad_norm": 1.652109146118164,
      "learning_rate": 0.0001007288475757896,
      "loss": 2.9461,
      "step": 4800
    },
    {
      "epoch": 1.5209754567552731,
      "grad_norm": 1.5986747741699219,
      "learning_rate": 9.967254674131194e-05,
      "loss": 2.9404,
      "step": 4850
    },
    {
      "epoch": 1.5366580412451971,
      "grad_norm": 1.8411270380020142,
      "learning_rate": 9.861624590683428e-05,
      "loss": 2.9511,
      "step": 4900
    },
    {
      "epoch": 1.552340625735121,
      "grad_norm": 1.5210820436477661,
      "learning_rate": 9.75599450723566e-05,
      "loss": 2.9366,
      "step": 4950
    },
    {
      "epoch": 1.568023210225045,
      "grad_norm": 1.8350539207458496,
      "learning_rate": 9.650364423787895e-05,
      "loss": 2.9394,
      "step": 5000
    },
    {
      "epoch": 1.568023210225045,
      "eval_loss": 2.939695358276367,
      "eval_runtime": 46.4498,
      "eval_samples_per_second": 243.962,
      "eval_steps_per_second": 30.506,
      "step": 5000
    },
    {
      "epoch": 1.583705794714969,
      "grad_norm": 1.7308307886123657,
      "learning_rate": 9.544734340340129e-05,
      "loss": 2.9449,
      "step": 5050
    },
    {
      "epoch": 1.599388379204893,
      "grad_norm": 1.5894204378128052,
      "learning_rate": 9.439104256892364e-05,
      "loss": 2.9369,
      "step": 5100
    },
    {
      "epoch": 1.615070963694817,
      "grad_norm": 1.6731138229370117,
      "learning_rate": 9.333474173444597e-05,
      "loss": 2.9396,
      "step": 5150
    },
    {
      "epoch": 1.6307535481847408,
      "grad_norm": 1.6405750513076782,
      "learning_rate": 9.227844089996831e-05,
      "loss": 2.9419,
      "step": 5200
    },
    {
      "epoch": 1.6464361326746648,
      "grad_norm": 1.5627464056015015,
      "learning_rate": 9.122214006549066e-05,
      "loss": 2.9433,
      "step": 5250
    },
    {
      "epoch": 1.6621187171645886,
      "grad_norm": 1.525978922843933,
      "learning_rate": 9.0165839231013e-05,
      "loss": 2.9341,
      "step": 5300
    },
    {
      "epoch": 1.6778013016545126,
      "grad_norm": 3.730633497238159,
      "learning_rate": 8.91306644132249e-05,
      "loss": 2.9231,
      "step": 5350
    },
    {
      "epoch": 1.6934838861444366,
      "grad_norm": 1.5684895515441895,
      "learning_rate": 8.807436357874724e-05,
      "loss": 2.9315,
      "step": 5400
    },
    {
      "epoch": 1.7091664706343606,
      "grad_norm": 1.528380036354065,
      "learning_rate": 8.701806274426956e-05,
      "loss": 2.9369,
      "step": 5450
    },
    {
      "epoch": 1.7248490551242845,
      "grad_norm": 1.7813390493392944,
      "learning_rate": 8.596176190979192e-05,
      "loss": 2.9347,
      "step": 5500
    },
    {
      "epoch": 1.7248490551242845,
      "eval_loss": 2.935861825942993,
      "eval_runtime": 46.483,
      "eval_samples_per_second": 243.788,
      "eval_steps_per_second": 30.484,
      "step": 5500
    },
    {
      "epoch": 1.7405316396142085,
      "grad_norm": 1.5480209589004517,
      "learning_rate": 8.490546107531426e-05,
      "loss": 2.939,
      "step": 5550
    },
    {
      "epoch": 1.7562142241041325,
      "grad_norm": 1.543177843093872,
      "learning_rate": 8.38491602408366e-05,
      "loss": 2.9373,
      "step": 5600
    },
    {
      "epoch": 1.7718968085940563,
      "grad_norm": 1.6391699314117432,
      "learning_rate": 8.279285940635893e-05,
      "loss": 2.9528,
      "step": 5650
    },
    {
      "epoch": 1.7875793930839803,
      "grad_norm": 1.4926317930221558,
      "learning_rate": 8.173655857188127e-05,
      "loss": 2.9405,
      "step": 5700
    },
    {
      "epoch": 1.803261977573904,
      "grad_norm": 1.783782720565796,
      "learning_rate": 8.068025773740362e-05,
      "loss": 2.944,
      "step": 5750
    },
    {
      "epoch": 1.818944562063828,
      "grad_norm": 1.4612751007080078,
      "learning_rate": 7.962395690292595e-05,
      "loss": 2.9347,
      "step": 5800
    },
    {
      "epoch": 1.834627146553752,
      "grad_norm": 1.4959673881530762,
      "learning_rate": 7.85676560684483e-05,
      "loss": 2.931,
      "step": 5850
    },
    {
      "epoch": 1.850309731043676,
      "grad_norm": 1.790878415107727,
      "learning_rate": 7.751135523397064e-05,
      "loss": 2.9373,
      "step": 5900
    },
    {
      "epoch": 1.8659923155336,
      "grad_norm": 1.5913302898406982,
      "learning_rate": 7.645505439949298e-05,
      "loss": 2.9289,
      "step": 5950
    },
    {
      "epoch": 1.881674900023524,
      "grad_norm": 1.667563557624817,
      "learning_rate": 7.539875356501532e-05,
      "loss": 2.9388,
      "step": 6000
    },
    {
      "epoch": 1.881674900023524,
      "eval_loss": 2.9313199520111084,
      "eval_runtime": 46.2061,
      "eval_samples_per_second": 245.249,
      "eval_steps_per_second": 30.667,
      "step": 6000
    }
  ],
  "logging_steps": 50,
  "max_steps": 9567,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 3,
  "save_steps": 1000,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 2.6460463118155776e+16,
  "train_batch_size": 8,
  "trial_name": null,
  "trial_params": null
}
