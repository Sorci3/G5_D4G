{
  "best_global_step": 9000,
  "best_metric": 2.922433376312256,
  "best_model_checkpoint": "./pythia-70m-xsum-summarizer\\checkpoint-9000",
  "epoch": 2.8223947306516113,
  "eval_steps": 500,
  "global_step": 9000,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.01568258448992394,
      "grad_norm": 3.833181381225586,
      "learning_rate": 9.8e-05,
      "loss": 4.02,
      "step": 50
    },
    {
      "epoch": 0.03136516897984788,
      "grad_norm": 2.7710986137390137,
      "learning_rate": 0.00019800000000000002,
      "loss": 3.3396,
      "step": 100
    },
    {
      "epoch": 0.047047753469771816,
      "grad_norm": 2.5118908882141113,
      "learning_rate": 0.0001989648251822119,
      "loss": 3.1055,
      "step": 150
    },
    {
      "epoch": 0.06273033795969576,
      "grad_norm": 2.277897834777832,
      "learning_rate": 0.00019790852434773423,
      "loss": 3.0671,
      "step": 200
    },
    {
      "epoch": 0.0784129224496197,
      "grad_norm": 1.995082974433899,
      "learning_rate": 0.0001968522235132566,
      "loss": 3.0558,
      "step": 250
    },
    {
      "epoch": 0.09409550693954363,
      "grad_norm": 1.7604159116744995,
      "learning_rate": 0.00019579592267877894,
      "loss": 3.0333,
      "step": 300
    },
    {
      "epoch": 0.10977809142946758,
      "grad_norm": 1.7713491916656494,
      "learning_rate": 0.00019473962184430126,
      "loss": 3.0462,
      "step": 350
    },
    {
      "epoch": 0.12546067591939153,
      "grad_norm": 1.8713388442993164,
      "learning_rate": 0.00019368332100982362,
      "loss": 3.035,
      "step": 400
    },
    {
      "epoch": 0.14114326040931546,
      "grad_norm": 1.73073410987854,
      "learning_rate": 0.00019262702017534594,
      "loss": 3.0245,
      "step": 450
    },
    {
      "epoch": 0.1568258448992394,
      "grad_norm": 1.607773780822754,
      "learning_rate": 0.0001915707193408683,
      "loss": 3.0346,
      "step": 500
    },
    {
      "epoch": 0.1568258448992394,
      "eval_loss": 3.0135490894317627,
      "eval_runtime": 46.4716,
      "eval_samples_per_second": 243.848,
      "eval_steps_per_second": 30.492,
      "step": 500
    },
    {
      "epoch": 0.17250842938916333,
      "grad_norm": 1.966647744178772,
      "learning_rate": 0.00019051441850639062,
      "loss": 3.0221,
      "step": 550
    },
    {
      "epoch": 0.18819101387908727,
      "grad_norm": 1.6319724321365356,
      "learning_rate": 0.00018945811767191297,
      "loss": 3.0203,
      "step": 600
    },
    {
      "epoch": 0.2038735983690112,
      "grad_norm": 1.938615083694458,
      "learning_rate": 0.00018840181683743533,
      "loss": 3.0132,
      "step": 650
    },
    {
      "epoch": 0.21955618285893516,
      "grad_norm": 1.6289666891098022,
      "learning_rate": 0.00018734551600295765,
      "loss": 3.0072,
      "step": 700
    },
    {
      "epoch": 0.2352387673488591,
      "grad_norm": 1.390468716621399,
      "learning_rate": 0.00018628921516848,
      "loss": 3.0164,
      "step": 750
    },
    {
      "epoch": 0.25092135183878306,
      "grad_norm": 1.8141419887542725,
      "learning_rate": 0.00018523291433400233,
      "loss": 3.0059,
      "step": 800
    },
    {
      "epoch": 0.266603936328707,
      "grad_norm": 1.5383907556533813,
      "learning_rate": 0.00018417661349952465,
      "loss": 2.9813,
      "step": 850
    },
    {
      "epoch": 0.2822865208186309,
      "grad_norm": 1.6310404539108276,
      "learning_rate": 0.000183120312665047,
      "loss": 2.9947,
      "step": 900
    },
    {
      "epoch": 0.29796910530855486,
      "grad_norm": 1.4976071119308472,
      "learning_rate": 0.00018206401183056936,
      "loss": 2.9931,
      "step": 950
    },
    {
      "epoch": 0.3136516897984788,
      "grad_norm": 1.3926053047180176,
      "learning_rate": 0.0001810077109960917,
      "loss": 3.0005,
      "step": 1000
    },
    {
      "epoch": 0.3136516897984788,
      "eval_loss": 2.9893016815185547,
      "eval_runtime": 46.6213,
      "eval_samples_per_second": 243.065,
      "eval_steps_per_second": 30.394,
      "step": 1000
    },
    {
      "epoch": 0.32933427428840273,
      "grad_norm": 1.8714981079101562,
      "learning_rate": 0.00017995141016161404,
      "loss": 2.9844,
      "step": 1050
    },
    {
      "epoch": 0.34501685877832666,
      "grad_norm": 1.6839807033538818,
      "learning_rate": 0.0001788951093271364,
      "loss": 2.9841,
      "step": 1100
    },
    {
      "epoch": 0.3606994432682506,
      "grad_norm": 1.5096240043640137,
      "learning_rate": 0.0001778388084926587,
      "loss": 2.9955,
      "step": 1150
    },
    {
      "epoch": 0.37638202775817453,
      "grad_norm": 1.4713188409805298,
      "learning_rate": 0.00017678250765818104,
      "loss": 2.9864,
      "step": 1200
    },
    {
      "epoch": 0.39206461224809847,
      "grad_norm": 1.6477006673812866,
      "learning_rate": 0.0001757262068237034,
      "loss": 2.9817,
      "step": 1250
    },
    {
      "epoch": 0.4077471967380224,
      "grad_norm": 1.7117180824279785,
      "learning_rate": 0.00017466990598922574,
      "loss": 2.9868,
      "step": 1300
    },
    {
      "epoch": 0.4234297812279464,
      "grad_norm": 1.625845193862915,
      "learning_rate": 0.00017361360515474807,
      "loss": 2.9866,
      "step": 1350
    },
    {
      "epoch": 0.4391123657178703,
      "grad_norm": 1.7361077070236206,
      "learning_rate": 0.00017255730432027042,
      "loss": 2.9715,
      "step": 1400
    },
    {
      "epoch": 0.45479495020779426,
      "grad_norm": 1.4359303712844849,
      "learning_rate": 0.00017150100348579277,
      "loss": 2.9907,
      "step": 1450
    },
    {
      "epoch": 0.4704775346977182,
      "grad_norm": 1.5308500528335571,
      "learning_rate": 0.00017044470265131513,
      "loss": 2.9858,
      "step": 1500
    },
    {
      "epoch": 0.4704775346977182,
      "eval_loss": 2.9749133586883545,
      "eval_runtime": 46.5612,
      "eval_samples_per_second": 243.378,
      "eval_steps_per_second": 30.433,
      "step": 1500
    },
    {
      "epoch": 0.4861601191876421,
      "grad_norm": 1.4840519428253174,
      "learning_rate": 0.00016938840181683745,
      "loss": 2.9687,
      "step": 1550
    },
    {
      "epoch": 0.5018427036775661,
      "grad_norm": 2.3720390796661377,
      "learning_rate": 0.00016833210098235978,
      "loss": 2.9785,
      "step": 1600
    },
    {
      "epoch": 0.51752528816749,
      "grad_norm": 1.663994312286377,
      "learning_rate": 0.00016727580014788213,
      "loss": 2.9599,
      "step": 1650
    },
    {
      "epoch": 0.533207872657414,
      "grad_norm": 1.4365259408950806,
      "learning_rate": 0.00016621949931340445,
      "loss": 2.982,
      "step": 1700
    },
    {
      "epoch": 0.5488904571473379,
      "grad_norm": 1.6500166654586792,
      "learning_rate": 0.0001651631984789268,
      "loss": 2.9666,
      "step": 1750
    },
    {
      "epoch": 0.5645730416372619,
      "grad_norm": 1.490764856338501,
      "learning_rate": 0.00016410689764444916,
      "loss": 2.9673,
      "step": 1800
    },
    {
      "epoch": 0.5802556261271857,
      "grad_norm": 1.5859612226486206,
      "learning_rate": 0.00016305059680997148,
      "loss": 2.9658,
      "step": 1850
    },
    {
      "epoch": 0.5959382106171097,
      "grad_norm": 1.4504107236862183,
      "learning_rate": 0.00016199429597549384,
      "loss": 2.9643,
      "step": 1900
    },
    {
      "epoch": 0.6116207951070336,
      "grad_norm": 1.736838698387146,
      "learning_rate": 0.00016093799514101616,
      "loss": 2.9698,
      "step": 1950
    },
    {
      "epoch": 0.6273033795969576,
      "grad_norm": 1.5479280948638916,
      "learning_rate": 0.00015988169430653851,
      "loss": 2.9756,
      "step": 2000
    },
    {
      "epoch": 0.6273033795969576,
      "eval_loss": 2.967554807662964,
      "eval_runtime": 46.5694,
      "eval_samples_per_second": 243.336,
      "eval_steps_per_second": 30.428,
      "step": 2000
    },
    {
      "epoch": 0.6429859640868815,
      "grad_norm": 1.6957513093948364,
      "learning_rate": 0.00015882539347206084,
      "loss": 2.9765,
      "step": 2050
    },
    {
      "epoch": 0.6586685485768055,
      "grad_norm": 1.9758931398391724,
      "learning_rate": 0.0001577690926375832,
      "loss": 2.9739,
      "step": 2100
    },
    {
      "epoch": 0.6743511330667294,
      "grad_norm": 1.9542165994644165,
      "learning_rate": 0.00015671279180310554,
      "loss": 2.972,
      "step": 2150
    },
    {
      "epoch": 0.6900337175566533,
      "grad_norm": 1.4416577816009521,
      "learning_rate": 0.00015565649096862787,
      "loss": 2.9665,
      "step": 2200
    },
    {
      "epoch": 0.7057163020465773,
      "grad_norm": 1.3789575099945068,
      "learning_rate": 0.00015460019013415022,
      "loss": 2.9631,
      "step": 2250
    },
    {
      "epoch": 0.7213988865365012,
      "grad_norm": 1.5378917455673218,
      "learning_rate": 0.00015354388929967255,
      "loss": 2.9753,
      "step": 2300
    },
    {
      "epoch": 0.7370814710264252,
      "grad_norm": 1.6364811658859253,
      "learning_rate": 0.00015248758846519487,
      "loss": 2.9666,
      "step": 2350
    },
    {
      "epoch": 0.7527640555163491,
      "grad_norm": 1.326087474822998,
      "learning_rate": 0.00015143128763071723,
      "loss": 2.9663,
      "step": 2400
    },
    {
      "epoch": 0.768446640006273,
      "grad_norm": 1.4928799867630005,
      "learning_rate": 0.00015037498679623958,
      "loss": 2.9806,
      "step": 2450
    },
    {
      "epoch": 0.7841292244961969,
      "grad_norm": 1.6634109020233154,
      "learning_rate": 0.0001493186859617619,
      "loss": 2.9585,
      "step": 2500
    },
    {
      "epoch": 0.7841292244961969,
      "eval_loss": 2.9598798751831055,
      "eval_runtime": 46.7463,
      "eval_samples_per_second": 242.415,
      "eval_steps_per_second": 30.313,
      "step": 2500
    },
    {
      "epoch": 0.7998118089861209,
      "grad_norm": 1.856436014175415,
      "learning_rate": 0.00014826238512728426,
      "loss": 2.9662,
      "step": 2550
    },
    {
      "epoch": 0.8154943934760448,
      "grad_norm": 1.7303508520126343,
      "learning_rate": 0.0001472060842928066,
      "loss": 2.963,
      "step": 2600
    },
    {
      "epoch": 0.8311769779659688,
      "grad_norm": 1.5605945587158203,
      "learning_rate": 0.00014614978345832896,
      "loss": 2.9653,
      "step": 2650
    },
    {
      "epoch": 0.8468595624558928,
      "grad_norm": 1.703322410583496,
      "learning_rate": 0.00014509348262385129,
      "loss": 2.9542,
      "step": 2700
    },
    {
      "epoch": 0.8625421469458167,
      "grad_norm": 1.8575642108917236,
      "learning_rate": 0.0001440371817893736,
      "loss": 2.9629,
      "step": 2750
    },
    {
      "epoch": 0.8782247314357406,
      "grad_norm": 1.6529910564422607,
      "learning_rate": 0.00014298088095489596,
      "loss": 2.9639,
      "step": 2800
    },
    {
      "epoch": 0.8939073159256645,
      "grad_norm": 2.0566461086273193,
      "learning_rate": 0.0001419245801204183,
      "loss": 2.9565,
      "step": 2850
    },
    {
      "epoch": 0.9095899004155885,
      "grad_norm": 1.5267177820205688,
      "learning_rate": 0.00014086827928594064,
      "loss": 2.9552,
      "step": 2900
    },
    {
      "epoch": 0.9252724849055124,
      "grad_norm": 1.4600589275360107,
      "learning_rate": 0.000139811978451463,
      "loss": 2.9646,
      "step": 2950
    },
    {
      "epoch": 0.9409550693954364,
      "grad_norm": 1.4252005815505981,
      "learning_rate": 0.00013875567761698532,
      "loss": 2.9511,
      "step": 3000
    },
    {
      "epoch": 0.9409550693954364,
      "eval_loss": 2.9530112743377686,
      "eval_runtime": 46.7743,
      "eval_samples_per_second": 242.27,
      "eval_steps_per_second": 30.294,
      "step": 3000
    },
    {
      "epoch": 0.9566376538853603,
      "grad_norm": 1.533394694328308,
      "learning_rate": 0.00013769937678250767,
      "loss": 2.9515,
      "step": 3050
    },
    {
      "epoch": 0.9723202383752843,
      "grad_norm": 1.456629753112793,
      "learning_rate": 0.00013664307594803,
      "loss": 2.9531,
      "step": 3100
    },
    {
      "epoch": 0.9880028228652082,
      "grad_norm": 1.5567609071731567,
      "learning_rate": 0.00013558677511355235,
      "loss": 2.9566,
      "step": 3150
    },
    {
      "epoch": 1.0034501685877832,
      "grad_norm": 1.4663406610488892,
      "learning_rate": 0.00013453047427907467,
      "loss": 2.961,
      "step": 3200
    },
    {
      "epoch": 1.0191327530777072,
      "grad_norm": 2.0034031867980957,
      "learning_rate": 0.00013347417344459703,
      "loss": 2.9512,
      "step": 3250
    },
    {
      "epoch": 1.0348153375676312,
      "grad_norm": 1.5138664245605469,
      "learning_rate": 0.00013241787261011938,
      "loss": 2.9487,
      "step": 3300
    },
    {
      "epoch": 1.050497922057555,
      "grad_norm": 1.5865230560302734,
      "learning_rate": 0.0001313615717756417,
      "loss": 2.9619,
      "step": 3350
    },
    {
      "epoch": 1.066180506547479,
      "grad_norm": 1.8753890991210938,
      "learning_rate": 0.00013030527094116406,
      "loss": 2.9604,
      "step": 3400
    },
    {
      "epoch": 1.081863091037403,
      "grad_norm": 1.6500777006149292,
      "learning_rate": 0.0001292489701066864,
      "loss": 2.9565,
      "step": 3450
    },
    {
      "epoch": 1.097545675527327,
      "grad_norm": 1.5197460651397705,
      "learning_rate": 0.00012819266927220873,
      "loss": 2.9685,
      "step": 3500
    },
    {
      "epoch": 1.097545675527327,
      "eval_loss": 2.94925594329834,
      "eval_runtime": 46.723,
      "eval_samples_per_second": 242.536,
      "eval_steps_per_second": 30.328,
      "step": 3500
    },
    {
      "epoch": 1.1132282600172507,
      "grad_norm": 1.326562523841858,
      "learning_rate": 0.00012713636843773106,
      "loss": 2.9401,
      "step": 3550
    },
    {
      "epoch": 1.1289108445071747,
      "grad_norm": 1.6324068307876587,
      "learning_rate": 0.0001260800676032534,
      "loss": 2.9506,
      "step": 3600
    },
    {
      "epoch": 1.1445934289970987,
      "grad_norm": 1.5953855514526367,
      "learning_rate": 0.00012502376676877576,
      "loss": 2.958,
      "step": 3650
    },
    {
      "epoch": 1.1602760134870227,
      "grad_norm": 1.581068992614746,
      "learning_rate": 0.0001239674659342981,
      "loss": 2.9513,
      "step": 3700
    },
    {
      "epoch": 1.1759585979769467,
      "grad_norm": 1.6463632583618164,
      "learning_rate": 0.00012291116509982044,
      "loss": 2.9382,
      "step": 3750
    },
    {
      "epoch": 1.1916411824668705,
      "grad_norm": 1.6897501945495605,
      "learning_rate": 0.00012185486426534278,
      "loss": 2.9393,
      "step": 3800
    },
    {
      "epoch": 1.2073237669567944,
      "grad_norm": 1.6552120447158813,
      "learning_rate": 0.0001207985634308651,
      "loss": 2.9567,
      "step": 3850
    },
    {
      "epoch": 1.2230063514467184,
      "grad_norm": 1.4421063661575317,
      "learning_rate": 0.00011974226259638746,
      "loss": 2.9419,
      "step": 3900
    },
    {
      "epoch": 1.2386889359366424,
      "grad_norm": 1.5042452812194824,
      "learning_rate": 0.0001186859617619098,
      "loss": 2.9385,
      "step": 3950
    },
    {
      "epoch": 1.2543715204265662,
      "grad_norm": 1.595487117767334,
      "learning_rate": 0.00011762966092743212,
      "loss": 2.9408,
      "step": 4000
    },
    {
      "epoch": 1.2543715204265662,
      "eval_loss": 2.943643808364868,
      "eval_runtime": 47.0078,
      "eval_samples_per_second": 241.066,
      "eval_steps_per_second": 30.144,
      "step": 4000
    },
    {
      "epoch": 1.2700541049164902,
      "grad_norm": 1.6569511890411377,
      "learning_rate": 0.00011657336009295447,
      "loss": 2.9441,
      "step": 4050
    },
    {
      "epoch": 1.2857366894064142,
      "grad_norm": 1.6077288389205933,
      "learning_rate": 0.00011551705925847683,
      "loss": 2.9453,
      "step": 4100
    },
    {
      "epoch": 1.3014192738963382,
      "grad_norm": 1.6392207145690918,
      "learning_rate": 0.00011446075842399917,
      "loss": 2.9398,
      "step": 4150
    },
    {
      "epoch": 1.3171018583862621,
      "grad_norm": 1.7775018215179443,
      "learning_rate": 0.00011340445758952149,
      "loss": 2.9489,
      "step": 4200
    },
    {
      "epoch": 1.332784442876186,
      "grad_norm": 1.7078347206115723,
      "learning_rate": 0.00011234815675504384,
      "loss": 2.9369,
      "step": 4250
    },
    {
      "epoch": 1.34846702736611,
      "grad_norm": 1.5459624528884888,
      "learning_rate": 0.0001112918559205662,
      "loss": 2.9512,
      "step": 4300
    },
    {
      "epoch": 1.364149611856034,
      "grad_norm": 1.5739518404006958,
      "learning_rate": 0.00011023555508608852,
      "loss": 2.943,
      "step": 4350
    },
    {
      "epoch": 1.3798321963459579,
      "grad_norm": 1.5818517208099365,
      "learning_rate": 0.00010917925425161086,
      "loss": 2.9484,
      "step": 4400
    },
    {
      "epoch": 1.3955147808358817,
      "grad_norm": 1.6248295307159424,
      "learning_rate": 0.00010812295341713321,
      "loss": 2.954,
      "step": 4450
    },
    {
      "epoch": 1.4111973653258056,
      "grad_norm": 1.5167756080627441,
      "learning_rate": 0.00010706665258265554,
      "loss": 2.9449,
      "step": 4500
    },
    {
      "epoch": 1.4111973653258056,
      "eval_loss": 2.939418077468872,
      "eval_runtime": 46.5348,
      "eval_samples_per_second": 243.517,
      "eval_steps_per_second": 30.45,
      "step": 4500
    },
    {
      "epoch": 1.4268799498157296,
      "grad_norm": 1.656449317932129,
      "learning_rate": 0.00010601035174817788,
      "loss": 2.9297,
      "step": 4550
    },
    {
      "epoch": 1.4425625343056536,
      "grad_norm": 1.594496250152588,
      "learning_rate": 0.00010495405091370023,
      "loss": 2.9512,
      "step": 4600
    },
    {
      "epoch": 1.4582451187955776,
      "grad_norm": 1.4972716569900513,
      "learning_rate": 0.00010389775007922258,
      "loss": 2.9447,
      "step": 4650
    },
    {
      "epoch": 1.4739277032855014,
      "grad_norm": 1.5887229442596436,
      "learning_rate": 0.0001028414492447449,
      "loss": 2.9496,
      "step": 4700
    },
    {
      "epoch": 1.4896102877754254,
      "grad_norm": 1.473965048789978,
      "learning_rate": 0.00010178514841026725,
      "loss": 2.9462,
      "step": 4750
    },
    {
      "epoch": 1.5052928722653494,
      "grad_norm": 1.652109146118164,
      "learning_rate": 0.0001007288475757896,
      "loss": 2.9461,
      "step": 4800
    },
    {
      "epoch": 1.5209754567552731,
      "grad_norm": 1.5986747741699219,
      "learning_rate": 9.967254674131194e-05,
      "loss": 2.9404,
      "step": 4850
    },
    {
      "epoch": 1.5366580412451971,
      "grad_norm": 1.8411270380020142,
      "learning_rate": 9.861624590683428e-05,
      "loss": 2.9511,
      "step": 4900
    },
    {
      "epoch": 1.552340625735121,
      "grad_norm": 1.5210820436477661,
      "learning_rate": 9.75599450723566e-05,
      "loss": 2.9366,
      "step": 4950
    },
    {
      "epoch": 1.568023210225045,
      "grad_norm": 1.8350539207458496,
      "learning_rate": 9.650364423787895e-05,
      "loss": 2.9394,
      "step": 5000
    },
    {
      "epoch": 1.568023210225045,
      "eval_loss": 2.939695358276367,
      "eval_runtime": 46.4498,
      "eval_samples_per_second": 243.962,
      "eval_steps_per_second": 30.506,
      "step": 5000
    },
    {
      "epoch": 1.583705794714969,
      "grad_norm": 1.7308307886123657,
      "learning_rate": 9.544734340340129e-05,
      "loss": 2.9449,
      "step": 5050
    },
    {
      "epoch": 1.599388379204893,
      "grad_norm": 1.5894204378128052,
      "learning_rate": 9.439104256892364e-05,
      "loss": 2.9369,
      "step": 5100
    },
    {
      "epoch": 1.615070963694817,
      "grad_norm": 1.6731138229370117,
      "learning_rate": 9.333474173444597e-05,
      "loss": 2.9396,
      "step": 5150
    },
    {
      "epoch": 1.6307535481847408,
      "grad_norm": 1.6405750513076782,
      "learning_rate": 9.227844089996831e-05,
      "loss": 2.9419,
      "step": 5200
    },
    {
      "epoch": 1.6464361326746648,
      "grad_norm": 1.5627464056015015,
      "learning_rate": 9.122214006549066e-05,
      "loss": 2.9433,
      "step": 5250
    },
    {
      "epoch": 1.6621187171645886,
      "grad_norm": 1.525978922843933,
      "learning_rate": 9.0165839231013e-05,
      "loss": 2.9341,
      "step": 5300
    },
    {
      "epoch": 1.6778013016545126,
      "grad_norm": 3.730633497238159,
      "learning_rate": 8.91306644132249e-05,
      "loss": 2.9231,
      "step": 5350
    },
    {
      "epoch": 1.6934838861444366,
      "grad_norm": 1.5684895515441895,
      "learning_rate": 8.807436357874724e-05,
      "loss": 2.9315,
      "step": 5400
    },
    {
      "epoch": 1.7091664706343606,
      "grad_norm": 1.528380036354065,
      "learning_rate": 8.701806274426956e-05,
      "loss": 2.9369,
      "step": 5450
    },
    {
      "epoch": 1.7248490551242845,
      "grad_norm": 1.7813390493392944,
      "learning_rate": 8.596176190979192e-05,
      "loss": 2.9347,
      "step": 5500
    },
    {
      "epoch": 1.7248490551242845,
      "eval_loss": 2.935861825942993,
      "eval_runtime": 46.483,
      "eval_samples_per_second": 243.788,
      "eval_steps_per_second": 30.484,
      "step": 5500
    },
    {
      "epoch": 1.7405316396142085,
      "grad_norm": 1.5480209589004517,
      "learning_rate": 8.490546107531426e-05,
      "loss": 2.939,
      "step": 5550
    },
    {
      "epoch": 1.7562142241041325,
      "grad_norm": 1.543177843093872,
      "learning_rate": 8.38491602408366e-05,
      "loss": 2.9373,
      "step": 5600
    },
    {
      "epoch": 1.7718968085940563,
      "grad_norm": 1.6391699314117432,
      "learning_rate": 8.279285940635893e-05,
      "loss": 2.9528,
      "step": 5650
    },
    {
      "epoch": 1.7875793930839803,
      "grad_norm": 1.4926317930221558,
      "learning_rate": 8.173655857188127e-05,
      "loss": 2.9405,
      "step": 5700
    },
    {
      "epoch": 1.803261977573904,
      "grad_norm": 1.783782720565796,
      "learning_rate": 8.068025773740362e-05,
      "loss": 2.944,
      "step": 5750
    },
    {
      "epoch": 1.818944562063828,
      "grad_norm": 1.4612751007080078,
      "learning_rate": 7.962395690292595e-05,
      "loss": 2.9347,
      "step": 5800
    },
    {
      "epoch": 1.834627146553752,
      "grad_norm": 1.4959673881530762,
      "learning_rate": 7.85676560684483e-05,
      "loss": 2.931,
      "step": 5850
    },
    {
      "epoch": 1.850309731043676,
      "grad_norm": 1.790878415107727,
      "learning_rate": 7.751135523397064e-05,
      "loss": 2.9373,
      "step": 5900
    },
    {
      "epoch": 1.8659923155336,
      "grad_norm": 1.5913302898406982,
      "learning_rate": 7.645505439949298e-05,
      "loss": 2.9289,
      "step": 5950
    },
    {
      "epoch": 1.881674900023524,
      "grad_norm": 1.667563557624817,
      "learning_rate": 7.539875356501532e-05,
      "loss": 2.9388,
      "step": 6000
    },
    {
      "epoch": 1.881674900023524,
      "eval_loss": 2.9313199520111084,
      "eval_runtime": 46.2061,
      "eval_samples_per_second": 245.249,
      "eval_steps_per_second": 30.667,
      "step": 6000
    },
    {
      "epoch": 1.8973574845134478,
      "grad_norm": 1.5572408437728882,
      "learning_rate": 7.434245273053766e-05,
      "loss": 2.9341,
      "step": 6050
    },
    {
      "epoch": 1.9130400690033718,
      "grad_norm": 1.6584818363189697,
      "learning_rate": 7.328615189606001e-05,
      "loss": 2.936,
      "step": 6100
    },
    {
      "epoch": 1.9287226534932957,
      "grad_norm": 1.4721064567565918,
      "learning_rate": 7.222985106158235e-05,
      "loss": 2.9375,
      "step": 6150
    },
    {
      "epoch": 1.9444052379832195,
      "grad_norm": 1.5440424680709839,
      "learning_rate": 7.117355022710467e-05,
      "loss": 2.9384,
      "step": 6200
    },
    {
      "epoch": 1.9600878224731435,
      "grad_norm": 1.587185025215149,
      "learning_rate": 7.011724939262703e-05,
      "loss": 2.9336,
      "step": 6250
    },
    {
      "epoch": 1.9757704069630675,
      "grad_norm": 1.7383205890655518,
      "learning_rate": 6.906094855814936e-05,
      "loss": 2.9307,
      "step": 6300
    },
    {
      "epoch": 1.9914529914529915,
      "grad_norm": 1.537873387336731,
      "learning_rate": 6.80046477236717e-05,
      "loss": 2.9361,
      "step": 6350
    },
    {
      "epoch": 2.0069003371755665,
      "grad_norm": 1.7257938385009766,
      "learning_rate": 6.694834688919404e-05,
      "loss": 2.9367,
      "step": 6400
    },
    {
      "epoch": 2.0225829216654905,
      "grad_norm": 1.4105634689331055,
      "learning_rate": 6.589204605471638e-05,
      "loss": 2.9476,
      "step": 6450
    },
    {
      "epoch": 2.0382655061554145,
      "grad_norm": 1.6802685260772705,
      "learning_rate": 6.483574522023873e-05,
      "loss": 2.921,
      "step": 6500
    },
    {
      "epoch": 2.0382655061554145,
      "eval_loss": 2.9292476177215576,
      "eval_runtime": 46.5072,
      "eval_samples_per_second": 243.661,
      "eval_steps_per_second": 30.468,
      "step": 6500
    },
    {
      "epoch": 2.0539480906453385,
      "grad_norm": 1.6145541667938232,
      "learning_rate": 6.377944438576107e-05,
      "loss": 2.9243,
      "step": 6550
    },
    {
      "epoch": 2.0696306751352624,
      "grad_norm": 1.610804557800293,
      "learning_rate": 6.27231435512834e-05,
      "loss": 2.9407,
      "step": 6600
    },
    {
      "epoch": 2.0853132596251864,
      "grad_norm": 1.9521763324737549,
      "learning_rate": 6.166684271680575e-05,
      "loss": 2.9218,
      "step": 6650
    },
    {
      "epoch": 2.10099584411511,
      "grad_norm": 1.7558215856552124,
      "learning_rate": 6.061054188232809e-05,
      "loss": 2.9293,
      "step": 6700
    },
    {
      "epoch": 2.116678428605034,
      "grad_norm": 1.587110996246338,
      "learning_rate": 5.9554241047850435e-05,
      "loss": 2.9327,
      "step": 6750
    },
    {
      "epoch": 2.132361013094958,
      "grad_norm": 1.8306907415390015,
      "learning_rate": 5.8497940213372774e-05,
      "loss": 2.9389,
      "step": 6800
    },
    {
      "epoch": 2.148043597584882,
      "grad_norm": 1.7731047868728638,
      "learning_rate": 5.7441639378895106e-05,
      "loss": 2.924,
      "step": 6850
    },
    {
      "epoch": 2.163726182074806,
      "grad_norm": 1.5503132343292236,
      "learning_rate": 5.638533854441745e-05,
      "loss": 2.9269,
      "step": 6900
    },
    {
      "epoch": 2.17940876656473,
      "grad_norm": 1.7932435274124146,
      "learning_rate": 5.532903770993979e-05,
      "loss": 2.9171,
      "step": 6950
    },
    {
      "epoch": 2.195091351054654,
      "grad_norm": 1.7427676916122437,
      "learning_rate": 5.4272736875462136e-05,
      "loss": 2.9279,
      "step": 7000
    },
    {
      "epoch": 2.195091351054654,
      "eval_loss": 2.9303832054138184,
      "eval_runtime": 46.3066,
      "eval_samples_per_second": 244.717,
      "eval_steps_per_second": 30.6,
      "step": 7000
    },
    {
      "epoch": 2.210773935544578,
      "grad_norm": 1.9710816144943237,
      "learning_rate": 5.3216436040984475e-05,
      "loss": 2.9363,
      "step": 7050
    },
    {
      "epoch": 2.2264565200345015,
      "grad_norm": 1.643828272819519,
      "learning_rate": 5.2160135206506813e-05,
      "loss": 2.918,
      "step": 7100
    },
    {
      "epoch": 2.2421391045244254,
      "grad_norm": 1.7168543338775635,
      "learning_rate": 5.110383437202916e-05,
      "loss": 2.9395,
      "step": 7150
    },
    {
      "epoch": 2.2578216890143494,
      "grad_norm": 1.4586708545684814,
      "learning_rate": 5.004753353755149e-05,
      "loss": 2.9311,
      "step": 7200
    },
    {
      "epoch": 2.2735042735042734,
      "grad_norm": 1.5674654245376587,
      "learning_rate": 4.899123270307384e-05,
      "loss": 2.93,
      "step": 7250
    },
    {
      "epoch": 2.2891868579941974,
      "grad_norm": 1.8122323751449585,
      "learning_rate": 4.7934931868596176e-05,
      "loss": 2.9302,
      "step": 7300
    },
    {
      "epoch": 2.3048694424841214,
      "grad_norm": 1.493021011352539,
      "learning_rate": 4.687863103411852e-05,
      "loss": 2.933,
      "step": 7350
    },
    {
      "epoch": 2.3205520269740454,
      "grad_norm": 1.6296703815460205,
      "learning_rate": 4.582233019964086e-05,
      "loss": 2.9303,
      "step": 7400
    },
    {
      "epoch": 2.3362346114639694,
      "grad_norm": 1.55039381980896,
      "learning_rate": 4.47660293651632e-05,
      "loss": 2.9357,
      "step": 7450
    },
    {
      "epoch": 2.3519171959538934,
      "grad_norm": 2.0088322162628174,
      "learning_rate": 4.370972853068554e-05,
      "loss": 2.937,
      "step": 7500
    },
    {
      "epoch": 2.3519171959538934,
      "eval_loss": 2.926085948944092,
      "eval_runtime": 46.3256,
      "eval_samples_per_second": 244.616,
      "eval_steps_per_second": 30.588,
      "step": 7500
    },
    {
      "epoch": 2.3675997804438174,
      "grad_norm": 1.6692051887512207,
      "learning_rate": 4.265342769620788e-05,
      "loss": 2.9287,
      "step": 7550
    },
    {
      "epoch": 2.383282364933741,
      "grad_norm": 1.6130326986312866,
      "learning_rate": 4.159712686173022e-05,
      "loss": 2.9312,
      "step": 7600
    },
    {
      "epoch": 2.398964949423665,
      "grad_norm": 1.585376262664795,
      "learning_rate": 4.054082602725257e-05,
      "loss": 2.9269,
      "step": 7650
    },
    {
      "epoch": 2.414647533913589,
      "grad_norm": 1.6978836059570312,
      "learning_rate": 3.94845251927749e-05,
      "loss": 2.9176,
      "step": 7700
    },
    {
      "epoch": 2.430330118403513,
      "grad_norm": 1.6189028024673462,
      "learning_rate": 3.8428224358297245e-05,
      "loss": 2.9204,
      "step": 7750
    },
    {
      "epoch": 2.446012702893437,
      "grad_norm": 1.6745803356170654,
      "learning_rate": 3.7371923523819584e-05,
      "loss": 2.9257,
      "step": 7800
    },
    {
      "epoch": 2.461695287383361,
      "grad_norm": 1.5359324216842651,
      "learning_rate": 3.631562268934193e-05,
      "loss": 2.9312,
      "step": 7850
    },
    {
      "epoch": 2.477377871873285,
      "grad_norm": 1.6470701694488525,
      "learning_rate": 3.525932185486427e-05,
      "loss": 2.9356,
      "step": 7900
    },
    {
      "epoch": 2.493060456363209,
      "grad_norm": 1.7506930828094482,
      "learning_rate": 3.420302102038661e-05,
      "loss": 2.9286,
      "step": 7950
    },
    {
      "epoch": 2.5087430408531324,
      "grad_norm": 1.5893311500549316,
      "learning_rate": 3.3146720185908946e-05,
      "loss": 2.9231,
      "step": 8000
    },
    {
      "epoch": 2.5087430408531324,
      "eval_loss": 2.924670696258545,
      "eval_runtime": 46.3222,
      "eval_samples_per_second": 244.634,
      "eval_steps_per_second": 30.59,
      "step": 8000
    },
    {
      "epoch": 2.5244256253430564,
      "grad_norm": 1.6105188131332397,
      "learning_rate": 3.209041935143129e-05,
      "loss": 2.9162,
      "step": 8050
    },
    {
      "epoch": 2.5401082098329804,
      "grad_norm": 1.6118671894073486,
      "learning_rate": 3.103411851695363e-05,
      "loss": 2.9368,
      "step": 8100
    },
    {
      "epoch": 2.5557907943229043,
      "grad_norm": 1.719314455986023,
      "learning_rate": 2.9977817682475973e-05,
      "loss": 2.9157,
      "step": 8150
    },
    {
      "epoch": 2.5714733788128283,
      "grad_norm": 2.1995301246643066,
      "learning_rate": 2.892151684799831e-05,
      "loss": 2.934,
      "step": 8200
    },
    {
      "epoch": 2.5871559633027523,
      "grad_norm": 1.6290287971496582,
      "learning_rate": 2.786521601352065e-05,
      "loss": 2.9349,
      "step": 8250
    },
    {
      "epoch": 2.6028385477926763,
      "grad_norm": 1.7427070140838623,
      "learning_rate": 2.6808915179042993e-05,
      "loss": 2.9212,
      "step": 8300
    },
    {
      "epoch": 2.6185211322826003,
      "grad_norm": 1.6643396615982056,
      "learning_rate": 2.5752614344565335e-05,
      "loss": 2.9065,
      "step": 8350
    },
    {
      "epoch": 2.6342037167725243,
      "grad_norm": 1.679246187210083,
      "learning_rate": 2.4696313510087674e-05,
      "loss": 2.9333,
      "step": 8400
    },
    {
      "epoch": 2.6498863012624483,
      "grad_norm": 1.619128704071045,
      "learning_rate": 2.3640012675610016e-05,
      "loss": 2.9191,
      "step": 8450
    },
    {
      "epoch": 2.665568885752372,
      "grad_norm": 1.630692720413208,
      "learning_rate": 2.2583711841132355e-05,
      "loss": 2.9269,
      "step": 8500
    },
    {
      "epoch": 2.665568885752372,
      "eval_loss": 2.9230101108551025,
      "eval_runtime": 46.3711,
      "eval_samples_per_second": 244.377,
      "eval_steps_per_second": 30.558,
      "step": 8500
    },
    {
      "epoch": 2.681251470242296,
      "grad_norm": 1.766431212425232,
      "learning_rate": 2.1527411006654697e-05,
      "loss": 2.9193,
      "step": 8550
    },
    {
      "epoch": 2.69693405473222,
      "grad_norm": 1.6709414720535278,
      "learning_rate": 2.047111017217704e-05,
      "loss": 2.9326,
      "step": 8600
    },
    {
      "epoch": 2.712616639222144,
      "grad_norm": 1.6757402420043945,
      "learning_rate": 1.941480933769938e-05,
      "loss": 2.9308,
      "step": 8650
    },
    {
      "epoch": 2.728299223712068,
      "grad_norm": 1.451425313949585,
      "learning_rate": 1.835850850322172e-05,
      "loss": 2.9201,
      "step": 8700
    },
    {
      "epoch": 2.743981808201992,
      "grad_norm": 1.6943751573562622,
      "learning_rate": 1.730220766874406e-05,
      "loss": 2.9275,
      "step": 8750
    },
    {
      "epoch": 2.7596643926919158,
      "grad_norm": 1.6567081212997437,
      "learning_rate": 1.62459068342664e-05,
      "loss": 2.9199,
      "step": 8800
    },
    {
      "epoch": 2.7753469771818393,
      "grad_norm": 1.7888903617858887,
      "learning_rate": 1.5189605999788742e-05,
      "loss": 2.9302,
      "step": 8850
    },
    {
      "epoch": 2.7910295616717633,
      "grad_norm": 1.6898430585861206,
      "learning_rate": 1.4133305165311081e-05,
      "loss": 2.9294,
      "step": 8900
    },
    {
      "epoch": 2.8067121461616873,
      "grad_norm": 1.6997495889663696,
      "learning_rate": 1.3077004330833423e-05,
      "loss": 2.9352,
      "step": 8950
    },
    {
      "epoch": 2.8223947306516113,
      "grad_norm": 1.589563012123108,
      "learning_rate": 1.2020703496355764e-05,
      "loss": 2.9274,
      "step": 9000
    },
    {
      "epoch": 2.8223947306516113,
      "eval_loss": 2.922433376312256,
      "eval_runtime": 46.3456,
      "eval_samples_per_second": 244.511,
      "eval_steps_per_second": 30.575,
      "step": 9000
    }
  ],
  "logging_steps": 50,
  "max_steps": 9567,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 3,
  "save_steps": 1000,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 3.968893730370355e+16,
  "train_batch_size": 8,
  "trial_name": null,
  "trial_params": null
}
