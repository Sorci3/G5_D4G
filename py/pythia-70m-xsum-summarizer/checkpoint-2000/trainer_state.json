{
  "best_global_step": 2000,
  "best_metric": 2.967554807662964,
  "best_model_checkpoint": "./pythia-70m-xsum-summarizer\\checkpoint-2000",
  "epoch": 0.6273033795969576,
  "eval_steps": 500,
  "global_step": 2000,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.01568258448992394,
      "grad_norm": 3.833181381225586,
      "learning_rate": 9.8e-05,
      "loss": 4.02,
      "step": 50
    },
    {
      "epoch": 0.03136516897984788,
      "grad_norm": 2.7710986137390137,
      "learning_rate": 0.00019800000000000002,
      "loss": 3.3396,
      "step": 100
    },
    {
      "epoch": 0.047047753469771816,
      "grad_norm": 2.5118908882141113,
      "learning_rate": 0.0001989648251822119,
      "loss": 3.1055,
      "step": 150
    },
    {
      "epoch": 0.06273033795969576,
      "grad_norm": 2.277897834777832,
      "learning_rate": 0.00019790852434773423,
      "loss": 3.0671,
      "step": 200
    },
    {
      "epoch": 0.0784129224496197,
      "grad_norm": 1.995082974433899,
      "learning_rate": 0.0001968522235132566,
      "loss": 3.0558,
      "step": 250
    },
    {
      "epoch": 0.09409550693954363,
      "grad_norm": 1.7604159116744995,
      "learning_rate": 0.00019579592267877894,
      "loss": 3.0333,
      "step": 300
    },
    {
      "epoch": 0.10977809142946758,
      "grad_norm": 1.7713491916656494,
      "learning_rate": 0.00019473962184430126,
      "loss": 3.0462,
      "step": 350
    },
    {
      "epoch": 0.12546067591939153,
      "grad_norm": 1.8713388442993164,
      "learning_rate": 0.00019368332100982362,
      "loss": 3.035,
      "step": 400
    },
    {
      "epoch": 0.14114326040931546,
      "grad_norm": 1.73073410987854,
      "learning_rate": 0.00019262702017534594,
      "loss": 3.0245,
      "step": 450
    },
    {
      "epoch": 0.1568258448992394,
      "grad_norm": 1.607773780822754,
      "learning_rate": 0.0001915707193408683,
      "loss": 3.0346,
      "step": 500
    },
    {
      "epoch": 0.1568258448992394,
      "eval_loss": 3.0135490894317627,
      "eval_runtime": 46.4716,
      "eval_samples_per_second": 243.848,
      "eval_steps_per_second": 30.492,
      "step": 500
    },
    {
      "epoch": 0.17250842938916333,
      "grad_norm": 1.966647744178772,
      "learning_rate": 0.00019051441850639062,
      "loss": 3.0221,
      "step": 550
    },
    {
      "epoch": 0.18819101387908727,
      "grad_norm": 1.6319724321365356,
      "learning_rate": 0.00018945811767191297,
      "loss": 3.0203,
      "step": 600
    },
    {
      "epoch": 0.2038735983690112,
      "grad_norm": 1.938615083694458,
      "learning_rate": 0.00018840181683743533,
      "loss": 3.0132,
      "step": 650
    },
    {
      "epoch": 0.21955618285893516,
      "grad_norm": 1.6289666891098022,
      "learning_rate": 0.00018734551600295765,
      "loss": 3.0072,
      "step": 700
    },
    {
      "epoch": 0.2352387673488591,
      "grad_norm": 1.390468716621399,
      "learning_rate": 0.00018628921516848,
      "loss": 3.0164,
      "step": 750
    },
    {
      "epoch": 0.25092135183878306,
      "grad_norm": 1.8141419887542725,
      "learning_rate": 0.00018523291433400233,
      "loss": 3.0059,
      "step": 800
    },
    {
      "epoch": 0.266603936328707,
      "grad_norm": 1.5383907556533813,
      "learning_rate": 0.00018417661349952465,
      "loss": 2.9813,
      "step": 850
    },
    {
      "epoch": 0.2822865208186309,
      "grad_norm": 1.6310404539108276,
      "learning_rate": 0.000183120312665047,
      "loss": 2.9947,
      "step": 900
    },
    {
      "epoch": 0.29796910530855486,
      "grad_norm": 1.4976071119308472,
      "learning_rate": 0.00018206401183056936,
      "loss": 2.9931,
      "step": 950
    },
    {
      "epoch": 0.3136516897984788,
      "grad_norm": 1.3926053047180176,
      "learning_rate": 0.0001810077109960917,
      "loss": 3.0005,
      "step": 1000
    },
    {
      "epoch": 0.3136516897984788,
      "eval_loss": 2.9893016815185547,
      "eval_runtime": 46.6213,
      "eval_samples_per_second": 243.065,
      "eval_steps_per_second": 30.394,
      "step": 1000
    },
    {
      "epoch": 0.32933427428840273,
      "grad_norm": 1.8714981079101562,
      "learning_rate": 0.00017995141016161404,
      "loss": 2.9844,
      "step": 1050
    },
    {
      "epoch": 0.34501685877832666,
      "grad_norm": 1.6839807033538818,
      "learning_rate": 0.0001788951093271364,
      "loss": 2.9841,
      "step": 1100
    },
    {
      "epoch": 0.3606994432682506,
      "grad_norm": 1.5096240043640137,
      "learning_rate": 0.0001778388084926587,
      "loss": 2.9955,
      "step": 1150
    },
    {
      "epoch": 0.37638202775817453,
      "grad_norm": 1.4713188409805298,
      "learning_rate": 0.00017678250765818104,
      "loss": 2.9864,
      "step": 1200
    },
    {
      "epoch": 0.39206461224809847,
      "grad_norm": 1.6477006673812866,
      "learning_rate": 0.0001757262068237034,
      "loss": 2.9817,
      "step": 1250
    },
    {
      "epoch": 0.4077471967380224,
      "grad_norm": 1.7117180824279785,
      "learning_rate": 0.00017466990598922574,
      "loss": 2.9868,
      "step": 1300
    },
    {
      "epoch": 0.4234297812279464,
      "grad_norm": 1.625845193862915,
      "learning_rate": 0.00017361360515474807,
      "loss": 2.9866,
      "step": 1350
    },
    {
      "epoch": 0.4391123657178703,
      "grad_norm": 1.7361077070236206,
      "learning_rate": 0.00017255730432027042,
      "loss": 2.9715,
      "step": 1400
    },
    {
      "epoch": 0.45479495020779426,
      "grad_norm": 1.4359303712844849,
      "learning_rate": 0.00017150100348579277,
      "loss": 2.9907,
      "step": 1450
    },
    {
      "epoch": 0.4704775346977182,
      "grad_norm": 1.5308500528335571,
      "learning_rate": 0.00017044470265131513,
      "loss": 2.9858,
      "step": 1500
    },
    {
      "epoch": 0.4704775346977182,
      "eval_loss": 2.9749133586883545,
      "eval_runtime": 46.5612,
      "eval_samples_per_second": 243.378,
      "eval_steps_per_second": 30.433,
      "step": 1500
    },
    {
      "epoch": 0.4861601191876421,
      "grad_norm": 1.4840519428253174,
      "learning_rate": 0.00016938840181683745,
      "loss": 2.9687,
      "step": 1550
    },
    {
      "epoch": 0.5018427036775661,
      "grad_norm": 2.3720390796661377,
      "learning_rate": 0.00016833210098235978,
      "loss": 2.9785,
      "step": 1600
    },
    {
      "epoch": 0.51752528816749,
      "grad_norm": 1.663994312286377,
      "learning_rate": 0.00016727580014788213,
      "loss": 2.9599,
      "step": 1650
    },
    {
      "epoch": 0.533207872657414,
      "grad_norm": 1.4365259408950806,
      "learning_rate": 0.00016621949931340445,
      "loss": 2.982,
      "step": 1700
    },
    {
      "epoch": 0.5488904571473379,
      "grad_norm": 1.6500166654586792,
      "learning_rate": 0.0001651631984789268,
      "loss": 2.9666,
      "step": 1750
    },
    {
      "epoch": 0.5645730416372619,
      "grad_norm": 1.490764856338501,
      "learning_rate": 0.00016410689764444916,
      "loss": 2.9673,
      "step": 1800
    },
    {
      "epoch": 0.5802556261271857,
      "grad_norm": 1.5859612226486206,
      "learning_rate": 0.00016305059680997148,
      "loss": 2.9658,
      "step": 1850
    },
    {
      "epoch": 0.5959382106171097,
      "grad_norm": 1.4504107236862183,
      "learning_rate": 0.00016199429597549384,
      "loss": 2.9643,
      "step": 1900
    },
    {
      "epoch": 0.6116207951070336,
      "grad_norm": 1.736838698387146,
      "learning_rate": 0.00016093799514101616,
      "loss": 2.9698,
      "step": 1950
    },
    {
      "epoch": 0.6273033795969576,
      "grad_norm": 1.5479280948638916,
      "learning_rate": 0.00015988169430653851,
      "loss": 2.9756,
      "step": 2000
    },
    {
      "epoch": 0.6273033795969576,
      "eval_loss": 2.967554807662964,
      "eval_runtime": 46.5694,
      "eval_samples_per_second": 243.336,
      "eval_steps_per_second": 30.428,
      "step": 2000
    }
  ],
  "logging_steps": 50,
  "max_steps": 9567,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 3,
  "save_steps": 1000,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 8821325955072000.0,
  "train_batch_size": 8,
  "trial_name": null,
  "trial_params": null
}
